{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gogie607/Gogie607/blob/main/03_pytorch_computer_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96639262-d97e-42c8-9ade-f9e54f6a5661",
      "metadata": {
        "id": "96639262-d97e-42c8-9ade-f9e54f6a5661"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/03_pytorch_computer_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "[View Source Code](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/03_pytorch_computer_vision.ipynb) | [View Slides](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/slides/03_pytorch_computer_vision.pdf) | [Watch Video Walkthrough (Chapter 92)](https://youtu.be/V_xro1bcAuA&t=50445)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a5400eb-653b-46f1-88a6-079b01c4fb7d",
      "metadata": {
        "id": "8a5400eb-653b-46f1-88a6-079b01c4fb7d"
      },
      "source": [
        "# 03. PyTorch Computer Vision\n",
        "\n",
        "[Computer vision](https://en.wikipedia.org/wiki/Computer_vision) is the art of teaching a computer to see.\n",
        "\n",
        "Specifically, we're going to cover:\n",
        "\n",
        "| **Topic** | **Contents** |\n",
        "| ----- | ----- |\n",
        "| **0. Computer vision libraries in PyTorch** | PyTorch has a bunch of built-in helpful computer vision libraries, let's check them out.  |\n",
        "| **1. Load data** | To practice computer vision, we'll start with some images of different pieces of clothing from [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). |\n",
        "| **2. Prepare data** | We've got some images, let's load them in with a [PyTorch `DataLoader`](https://pytorch.org/docs/stable/data.html) so we can use them with our training loop. |\n",
        "| **3. Model 0: Building a baseline model** | Here we'll create a multi-class classification model to learn patterns in the data, we'll also choose a **loss function**, **optimizer** and build a **training loop**. |\n",
        "| **4. Making predictions and evaluating model 0** | Let's make some predictions with our baseline model and evaluate them. |\n",
        "| **5. Setup device agnostic code for future models** | It's best practice to write device-agnostic code, so let's set it up. |\n",
        "| **6. Model 1: Adding non-linearity** | Experimenting is a large part of machine learning, let's try and improve upon our baseline model by adding non-linear layers. |\n",
        "| **7. Model 2: Convolutional Neural Network (CNN)** | Time to get computer vision specific and introduce the powerful convolutional neural network architecture. |\n",
        "| **8. Comparing our models** | We've built three different models, let's compare them. |\n",
        "| **9. Evaluating our best model** | Let's make some predictions on random images and evaluate our best model. |\n",
        "| **10. Making a confusion matrix** | A confusion matrix is a great way to evaluate a classification model, let's see how we can make one. |\n",
        "| **11. Saving and loading the best performing model** | Since we might want to use our model for later, let's save it and make sure it loads back in correctly. |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ae4f7a61-89c4-41ec-9923-7760f2415d7a",
      "metadata": {
        "id": "ae4f7a61-89c4-41ec-9923-7760f2415d7a"
      },
      "outputs": [],
      "source": [
        "\n",
        "from IPython.display import clear_output\n",
        "import torch\n",
        "# example  of timestamp used in youtube\n",
        "#chapter 61 at 8:41:43  hour + 3600 *(min/60) + sec\n",
        "# the video ID I am watching is https://youtu.be/V_xro1bcAuA&t=timestamp\n",
        "def get_timestamp(h:torch.int,m:torch.int,s:torch.int):\n",
        "    return(3600 * h + (60*m) + s)\n",
        "#(8. + (41/60)) * 3600 + 43\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23ff1e7c-b060-4092-b112-71c6b03f7ea3",
      "metadata": {
        "id": "23ff1e7c-b060-4092-b112-71c6b03f7ea3"
      },
      "source": [
        "## 0. Computer vision libraries in PyTorch\n",
        "\n",
        "Before we get started writing code, let's talk about some PyTorch computer vision libraries you should be aware of.\n",
        "\n",
        "| PyTorch module | What does it do? |\n",
        "| ----- | ----- |\n",
        "| [`torchvision`](https://pytorch.org/vision/stable/index.html) | Contains datasets, model architectures and image transformations often used for computer vision problems. |\n",
        "| [`torchvision.datasets`](https://pytorch.org/vision/stable/datasets.html) | Here you'll find many example computer vision datasets for a range of problems from image classification, object detection, image captioning, video classification and more. It also contains [a series of base classes for making custom datasets](https://pytorch.org/vision/stable/datasets.html#base-classes-for-custom-datasets). |\n",
        "| [`torchvision.models`](https://pytorch.org/vision/stable/models.html) | This module contains well-performing and commonly used computer vision model architectures implemented in PyTorch, you can use these with your own problems. |\n",
        "| [`torchvision.transforms`](https://pytorch.org/vision/stable/transforms.html) | Often images need to be transformed (turned into numbers/processed/augmented) before being used with a model, common image transformations are found here. |\n",
        "| [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) | Base dataset class for PyTorch.  |\n",
        "| [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#module-torch.utils.data) | Creates a Python iterable over a dataset (created with `torch.utils.data.Dataset`). |\n",
        "\n",
        "> **Note:** The `torch.utils.data.Dataset` and `torch.utils.data.DataLoader` classes aren't only for computer vision in PyTorch, they are capable of dealing with many different types of data.\n",
        "\n",
        "Now we've covered some of the most important PyTorch computer vision libraries, let's import the relevant dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bd73bf1f-f03c-4705-aae6-3362914ea3d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd73bf1f-f03c-4705-aae6-3362914ea3d5",
        "outputId": "51a67d6c-eee5-409a-81c1-0e53bb5ed00a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.5.0+cu121\n",
            "torchvision version: 0.20.0+cu121\n",
            "Cuda version: 12.1\n",
            "Is Cuda available: True\n",
            "Cuda device name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "#import the basic libraries we use\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# new torchvision stuff\n",
        "import torchvision\n",
        "from torchvision import datasets, models\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# matplotlib for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check versions\n",
        "# Note: your PyTorch version shouldn't be lower than 1.10.0 and torchvision version shouldn't be lower than 0.11\n",
        "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")\n",
        "print(f\"Cuda version: {torch.version.cuda}\")\n",
        "print(f\"Is Cuda available: {torch.cuda.is_available()}\")\n",
        "print(f\"Cuda device name: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b09c675-8ae8-42af-8967-86cabf668521",
      "metadata": {
        "id": "5b09c675-8ae8-42af-8967-86cabf668521"
      },
      "source": [
        " **Chapter 93** 14,12.04 51159  94 (14,22,48)  95 (14,27,50)\n",
        " [Chapter 96)](https://youtu.be/V_xro1bcAuA&t=52630)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a67d350-0e0f-403b-8174-c71b22a5fd34",
      "metadata": {
        "id": "0a67d350-0e0f-403b-8174-c71b22a5fd34"
      },
      "source": [
        "## 1. Getting a dataset  \n",
        "To begin working on a computer vision problewm, let's get a dataset.\n",
        "\n",
        "We're going to start with [FashionMNIST](https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html#torchvision.datasets.FashionMNIST)...\n",
        "\n",
        "Later, we'll be building a computer vision neural network to identify the different styles of clothing in these images.\n",
        "\n",
        "PyTorch has a bunch of common computer vision datasets stored in torchvision.datasets.\n",
        "\n",
        "Including FashionMNIST in torchvision.datasets.FashionMNIST().\n",
        "\n",
        "To download it, we provide the following parameters:\n",
        "\n",
        "root: str - which folder do you want to download the data to?\n",
        "train: Bool - do you want the training or test split?\n",
        "download: Bool - should the data be downloaded?\n",
        "transform: torchvision.transforms - what transformations would you like to do on the data?\n",
        "target_transform - you can transform the targets (labels) if you like too.\n",
        "Many other datasets in torchvision have these parameter options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "feb14381-8b86-43a9-8d9c-9f27ce0f69a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feb14381-8b86-43a9-8d9c-9f27ce0f69a6",
        "outputId": "3c9d8165-e62c-420d-dc05-b84f8fcc4640"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 13.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 213kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.92MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 21.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# setup training data\n",
        "from torchvision import datasets\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root='data', #where to put data\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        "    target_transform=None\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhKqGJyrxlEG",
        "outputId": "a2d2cebf-f444-493e-932a-7f0fd45115f0"
      },
      "id": "FhKqGJyrxlEG",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8b8845ec-9864-4f2d-93eb-0413fa211b2b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b8845ec-9864-4f2d-93eb-0413fa211b2b",
        "outputId": "0aa11f3b-acf7-46da-c750-9bf1f301a219"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "len(train_data), len(test_data                 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e95bcb8f-d696-4cc7-b7d0-dc1dbea774d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e95bcb8f-d696-4cc7-b7d0-dc1dbea774d4",
        "outputId": "863e9650-c6b2-4698-c5c7-4808eb761d6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
              "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
              "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
              "           0.0157, 0.0000, 0.0000, 0.0118],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
              "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0471, 0.0392, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
              "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
              "           0.3020, 0.5098, 0.2824, 0.0588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
              "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
              "           0.5529, 0.3451, 0.6745, 0.2588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
              "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
              "           0.4824, 0.7686, 0.8980, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
              "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
              "           0.8745, 0.9608, 0.6784, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
              "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
              "           0.8627, 0.9529, 0.7922, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
              "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
              "           0.8863, 0.7725, 0.8196, 0.2039],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
              "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
              "           0.9608, 0.4667, 0.6549, 0.2196],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
              "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
              "           0.8510, 0.8196, 0.3608, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
              "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
              "           0.8549, 1.0000, 0.3020, 0.0000],\n",
              "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
              "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
              "           0.8784, 0.9569, 0.6235, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
              "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
              "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
              "           0.9137, 0.9333, 0.8431, 0.0000],\n",
              "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
              "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
              "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
              "           0.8627, 0.9098, 0.9647, 0.0000],\n",
              "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
              "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
              "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
              "           0.8706, 0.8941, 0.8824, 0.0000],\n",
              "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
              "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
              "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
              "           0.8745, 0.8784, 0.8980, 0.1137],\n",
              "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
              "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
              "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
              "           0.8627, 0.8667, 0.9020, 0.2627],\n",
              "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
              "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
              "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
              "           0.7098, 0.8039, 0.8078, 0.4510],\n",
              "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
              "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
              "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
              "           0.6549, 0.6941, 0.8235, 0.3608],\n",
              "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
              "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
              "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
              "           0.7529, 0.8471, 0.6667, 0.0000],\n",
              "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
              "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
              "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
              "           0.3882, 0.2275, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
              "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
              " 9)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "image,label = train_data[0]\n",
        "image[:1],label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f4f6fa8f-b92b-45d7-9eba-cd2eaee2ebbc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4f6fa8f-b92b-45d7-9eba-cd2eaee2ebbc",
        "outputId": "3d6274d8-7a3a-4fde-968c-fb79adc95c63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['T-shirt/top',\n",
              " 'Trouser',\n",
              " 'Pullover',\n",
              " 'Dress',\n",
              " 'Coat',\n",
              " 'Sandal',\n",
              " 'Shirt',\n",
              " 'Sneaker',\n",
              " 'Bag',\n",
              " 'Ankle boot']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "class_names = train_data.classes\n",
        "class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a6da2c8e-3049-4a8e-a353-bb8ac0b7e177",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6da2c8e-3049-4a8e-a353-bb8ac0b7e177",
        "outputId": "91ed2010-45a7-41c8-c3c9-0a28db0767fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'T-shirt/top': 0,\n",
              " 'Trouser': 1,\n",
              " 'Pullover': 2,\n",
              " 'Dress': 3,\n",
              " 'Coat': 4,\n",
              " 'Sandal': 5,\n",
              " 'Shirt': 6,\n",
              " 'Sneaker': 7,\n",
              " 'Bag': 8,\n",
              " 'Ankle boot': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "class_to_idx = train_data.class_to_idx\n",
        "class_to_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2dbf6a0c-d1b9-43ba-bd53-bef80dc061be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dbf6a0c-d1b9-43ba-bd53-bef80dc061be",
        "outputId": "130bfa7c-21fa-4a9d-bcda-ffb163976cea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image.shape torch.Size([1, 28, 28]) ->[color_channel, height, width]\n",
            "Label: Ankle boot\n"
          ]
        }
      ],
      "source": [
        "print(f\"image.shape {image.shape} ->[color_channel, height, width]\")\n",
        "print(f\"Label: {class_names[label]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39350f0c-b469-4b5e-9409-9c10660e3599",
      "metadata": {
        "id": "39350f0c-b469-4b5e-9409-9c10660e3599"
      },
      "source": [
        "### 1.2 Visualizing our data | [Chapter 97](https://youtu.be/V_xro1bcAuA&t=53502)\n",
        "\n",
        "Plot image as an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3b3d0108-6e23-4c82-938d-ed58e9310709",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "3b3d0108-6e23-4c82-938d-ed58e9310709",
        "outputId": "4f7f640d-1e78-4c13-f391-58a8b28619aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image shape: torch.Size([1, 28, 28])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Ankle boot')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqQklEQVR4nO3de3SU9b3v8c/kNgmQTAghCVMCBJCLXKKlEKNyT4GoFBUtWs/e4HF7a2gL2K2LVkW7Xc0WW8pRqejeLVg3iLgPF2UrrYCEoiAFpdRaKaFBUEgQNJmQkOv8zh8cRkeuvzHhl4T3a61Zmpnnk+fHw5N8eDIz33iMMUYAAFxgUa4XAAC4OFFAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAwDlMmzZNHTp0OOd2o0aN0qhRo5psv6NGjdLAgQOb7PMBLQ0FhDbp17/+tTwej3JyclwvpVX6+c9/rlWrVrleBto4Cght0pIlS9SjRw9t27ZNxcXFrpfT6lBAuBAoILQ5JSUlevvttzVv3jx17txZS5Yscb0kAKdBAaHNWbJkiTp27Khrr71WN91002kLaN++ffJ4PPrFL36h5557Tr169ZLX69XQoUP1pz/96Zz72Llzpzp37qxRo0bp2LFjZ9yutrZWc+bMUe/eveX1epWZman7779ftbW15/3n2bFjh6688kolJCQoKytLCxcuPGWbw4cP64477lB6erri4+OVnZ2t559//pTtqqqqdN999ykzM1Ner1d9+/bVL37xC315KL7H41FVVZWef/55eTweeTweTZs27bzXC5w3A7Qx/fr1M3fccYcxxphNmzYZSWbbtm1h25SUlBhJ5vLLLze9e/c2jz/+uJk7d65JTU01Xbt2NXV1daFtp06datq3bx/6eNu2baZjx47m29/+tqmurg7dP3LkSDNy5MjQx42NjWbcuHGmXbt2ZsaMGebZZ58106dPNzExMWbSpEnn/HOMHDnS+P1+k5aWZqZPn26efPJJc/XVVxtJ5je/+U1ou+rqatO/f38TGxtrZs6caZ588kkzfPhwI8nMnz8/tF0wGDRjxowxHo/H/Mu//It5+umnzcSJE40kM2PGjNB2L7zwgvF6vWb48OHmhRdeMC+88IJ5++23z33gAUsUENqU7du3G0nmjTfeMMac+KbbtWtX86Mf/Shsu5MF1KlTJ/PZZ5+F7l+9erWRZF599dXQfV8uoM2bN5ukpCRz7bXXmpqamrDP+dUCeuGFF0xUVJT54x//GLbdwoULjSTz1ltvnfXPMnLkSCPJ/PKXvwzdV1tbay677DKTlpYWKsn58+cbSea//uu/QtvV1dWZ3Nxc06FDBxMIBIwxxqxatcpIMo899ljYfm666Sbj8XhMcXFx6L727dubqVOnnnV9wNfFj+DQpixZskTp6ekaPXq0pBM/TpoyZYqWLVumxsbGU7afMmWKOnbsGPp4+PDhkqR//OMfp2z75ptvavz48Ro7dqxWrFghr9d71rW8/PLL6t+/v/r166cjR46EbmPGjAl9vnOJiYnR3XffHfo4Li5Od999tw4fPqwdO3ZIkl577TVlZGTo1ltvDW0XGxurH/7whzp27JiKiopC20VHR+uHP/xh2D7uu+8+GWP0+uuvn3M9QFOigNBmNDY2atmyZRo9erRKSkpUXFys4uJi5eTkqKysTOvXrz8l061bt7CPT5bR559/HnZ/TU2Nrr32Wl1++eVavny54uLizrmePXv26K9//as6d+4cduvTp4+kE8/bnIvf71f79u3D7juZ37dvnyTpo48+0iWXXKKoqPAv5/79+4ceP/lfv9+vxMTEs24HXCgxrhcANJUNGzbo0KFDWrZsmZYtW3bK40uWLNG4cePC7ouOjj7t5zJf+U31Xq9X11xzjVavXq21a9fquuuuO+d6gsGgBg0apHnz5p328czMzHN+DqAto4DQZixZskRpaWlasGDBKY+tWLFCK1eu1MKFC5WQkGD9uT0ej5YsWaJJkybp5ptv1uuvv37OqQe9evXSn//8Z40dO1Yej8d6n5J08OBBVVVVhV0F/f3vf5ck9ejRQ5LUvXt37dq1S8FgMOwq6MMPPww9fvK/69atU2VlZdhV0Fe3O/nnBZobP4JDm3D8+HGtWLFC1113nW666aZTbtOnT1dlZaVeeeWViPcRFxenFStWaOjQoZo4caK2bdt21u2/+93v6pNPPtF//Md/nHa9VVVV59xnQ0ODnn322dDHdXV1evbZZ9W5c2cNGTJEknTNNdeotLRUL730UljuqaeeUocOHTRy5MjQdo2NjXr66afD9vGrX/1KHo9H+fn5ofvat2+v8vLyc64P+Dq4AkKb8Morr6iyslLf+c53Tvv4FVdcEXpT6pQpUyLeT0JCgtasWaMxY8YoPz9fRUVFZ5zX9k//9E9avny57rnnHr355pu66qqr1NjYqA8//FDLly/X73//e33rW9866/78fr8ef/xx7du3T3369NFLL72knTt36rnnnlNsbKwk6a677tKzzz6radOmaceOHerRo4f++7//W2+99Zbmz58futqZOHGiRo8erZ/+9Kfat2+fsrOz9Yc//EGrV6/WjBkz1KtXr9B+hwwZonXr1mnevHny+/3KyspirBGanuuX4QFNYeLEiSY+Pt5UVVWdcZtp06aZ2NhYc+TIkdDLsJ944olTtpNk5syZE/r4q+8DMsaYI0eOmEsvvdRkZGSYPXv2GGNOfRm2MSdeDv3444+bAQMGGK/Xazp27GiGDBliHn30UVNRUXHWP9PIkSPNgAEDzPbt201ubq6Jj4833bt3N08//fQp25aVlZnbb7/dpKammri4ODNo0CCzaNGiU7arrKw0M2fONH6/38TGxppLLrnEPPHEEyYYDIZt9+GHH5oRI0aYhIQEI4mXZKNZeIz5yrOtAABcADwHBABwggICADhBAQEAnKCAAABOUEAAACcoIACAEy3ujajBYFAHDx5UYmIi40AAoBUyxqiyslJ+v/+UIblf1uIK6ODBgwxpBIA24MCBA+ratesZH29xBXRybMjVukYxinW8GgCArQbVa7NeO+VXf3xVsxXQggUL9MQTT6i0tFTZ2dl66qmnNGzYsHPmTv7YLUaxivFQQADQ6vz/+TrnehqlWV6E8NJLL2nWrFmaM2eO3n33XWVnZ2v8+PHn9Qu4AAAXh2YpoHnz5unOO+/U7bffrksvvVQLFy5Uu3bt9Nvf/rY5dgcAaIWavIDq6uq0Y8cO5eXlfbGTqCjl5eVpy5Ytp2xfW1urQCAQdgMAtH1NXkBHjhxRY2Oj0tPTw+5PT09XaWnpKdsXFhbK5/OFbrwCDgAuDs7fiDp79mxVVFSEbgcOHHC9JADABdDkr4JLTU1VdHS0ysrKwu4vKytTRkbGKdt7vV55vd6mXgYAoIVr8iuguLg4DRkyROvXrw/dFwwGtX79euXm5jb17gAArVSzvA9o1qxZmjp1qr71rW9p2LBhmj9/vqqqqnT77bc3x+4AAK1QsxTQlClT9Omnn+rhhx9WaWmpLrvsMq1du/aUFyYAAC5eHmOMcb2ILwsEAvL5fBqlSUxCAIBWqMHUa6NWq6KiQklJSWfczvmr4AAAFycKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgRIzrBQAtisdjnzGm6ddxGtGdUqwzn4/vE9G+kpZujShnLYLj7YmJtc6Y+jrrTIsXybkaqWY6x7kCAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnGEYKfIknOto6YxoarDNRl11qnfnb3R3s93PcOiJJiq0aZp2JOR60388ftltnLuhg0UiGpUZwDsljfy1wIY+DJ8auKjzGSOfxZcEVEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4wTBS4Etshy5KkQ0jPTA+2TpzW+4frTNvfdrTOiNJH3kzrDMmwX4/MXm51pk+v/7EOtOwb791RpJkjH0kgvMhEtEdO0YWbGy0jwQCVtsbc37HgCsgAIATFBAAwIkmL6BHHnlEHo8n7NavX7+m3g0AoJVrlueABgwYoHXr1n2xkwh+rg4AaNuapRliYmKUkWH/JCYA4OLRLM8B7dmzR36/Xz179tRtt92m/fvP/AqU2tpaBQKBsBsAoO1r8gLKycnR4sWLtXbtWj3zzDMqKSnR8OHDVVlZedrtCwsL5fP5QrfMzMymXhIAoAVq8gLKz8/XzTffrMGDB2v8+PF67bXXVF5eruXLl592+9mzZ6uioiJ0O3DgQFMvCQDQAjX7qwOSk5PVp08fFRcXn/Zxr9crr9fb3MsAALQwzf4+oGPHjmnv3r3q0qVLc+8KANCKNHkB/fjHP1ZRUZH27dunt99+WzfccIOio6N16623NvWuAACtWJP/CO7jjz/WrbfeqqNHj6pz5866+uqrtXXrVnXu3LmpdwUAaMWavICWLVvW1J8SuGCCNTUXZD91lx+zztzk226diY+qt85IUlFU0DrzyQb7V7A2DrY/Dh/NS7TOBN+70jojSZ3etx/cmfTeIevMkRHfsM58OsR+UKokpW+1z3Rct9dqexOsk46ceztmwQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAE83+C+kAJzyeyHLGfsDjse9eYZ3550s3Wmf21ttPlO8a95l1RpJu9u+wD/0v+8zTu0daZ6r+4bPORLWPbHBn6RX2/0b/ZJL935Opb7DOdHw3sm/fUVPLrDOBup5W2zfU10irz2Mt1isBAKAJUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4ATTsHFhRTqlugW74oFt1pnRHT5ohpWc6huKbAp0lYmzzpQ3trfOzLn0f6wzn/ZJtM7Um8i+1f3nniutM8cimNYd3WD/dXHF/37POiNJk1P+ZJ2Z+38HWW3fYOrPazuugAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACYaR4sIykQ3HbMn2HEuzzhxN6mCdKW1Its50ij5mnZGkxKjj1pkesUesM5822g8WjY4NWmfqTLR1RpIeHfCqdaamf6x1JtbTaJ25Mv6gdUaSbv7gn60z7fWPiPZ1LlwBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATDCMFvqbOXvuBn/GeeutMnKfBOnOwvqN1RpL2HO9rnfl7wH4o64T0v1pn6iMYLBqtyIbgRjIk1B/7uXWmxtgPMLU/g064Kt1+sOjOCPd1LlwBAQCcoIAAAE5YF9CmTZs0ceJE+f1+eTwerVq1KuxxY4wefvhhdenSRQkJCcrLy9OePXuaar0AgDbCuoCqqqqUnZ2tBQsWnPbxuXPn6sknn9TChQv1zjvvqH379ho/frxqamq+9mIBAG2H9YsQ8vPzlZ+ff9rHjDGaP3++HnzwQU2aNEmS9Lvf/U7p6elatWqVbrnllq+3WgBAm9GkzwGVlJSotLRUeXl5oft8Pp9ycnK0ZcuW02Zqa2sVCATCbgCAtq9JC6i0tFSSlJ6eHnZ/enp66LGvKiwslM/nC90yMzObckkAgBbK+avgZs+erYqKitDtwIEDrpcEALgAmrSAMjIyJEllZWVh95eVlYUe+yqv16ukpKSwGwCg7WvSAsrKylJGRobWr18fui8QCOidd95Rbm5uU+4KANDKWb8K7tixYyouLg59XFJSop07dyolJUXdunXTjBkz9Nhjj+mSSy5RVlaWHnroIfn9fl1//fVNuW4AQCtnXUDbt2/X6NGjQx/PmjVLkjR16lQtXrxY999/v6qqqnTXXXepvLxcV199tdauXav4+PimWzUAoNXzGGMim9LXTAKBgHw+n0ZpkmI89gP60MJ5PPaRaPvhk6bBfnCnJEV3tB/eecuWv9jvx2P/ZfdpQ6J1Jjm62jojSUXl9sNI/3r09M/zns3P+r5inXm3uod1xh9nPyBUiuz47atLtc5c4j39q4TP5vXPs60zkpQZ/5l15g8zRlht39BQo80bH1VFRcVZn9d3/io4AMDFiQICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACesfx0D8LVEMHzdE2N/mkY6DfvAHf2tM2PavWqdebvmG9aZzjGV1pl6Yz9JXJK6eCusM4npNdaZ8sZ21pmUmGPWmcrGBOuMJLWLqrXORPL39M24I9aZmeu+aZ2RpMSBR60zSbF21yrB87y24QoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJxgGCkuKE9snHUmWGM/5DJSqX+ps84caYy1ziRHVVtn4jyN1pm6CIeRXplSYp35NIKBn+8ez7LOJEYft850jrIfECpJmbH2gzv/UpNpnXmtqrd15o7r1llnJOnF575tnYlb+7bV9lGm/vy2s14JAABNgAICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOXNzDSD2eyGIx9sMnPdERdH2UfSZYU2u/n6D9kMtImXr7YZ8X0v959mnrzIGGZOtMab19JjnafoBpoyI7x7ce91ln4qPObwDll3WOCVhnAkH7oaeRqgzGW2fqIxgAG8mxe6DTHuuMJK2oyIso1xy4AgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJ9rMMFJPjP0fxTQ0RLSvSAZqGvtZg23S8UnDrDMHrrcflnrb5dusM5JU2pBonXmvuod1xhd93DrTPsp+0GyNsR+cK0kH6zpaZyIZqJkSc8w6kxbBANNGE9m/tT+ptz8OkYhk0OzHDfbHTpIqv1NpnUn+XUS7OieugAAATlBAAAAnrAto06ZNmjhxovx+vzwej1atWhX2+LRp0+TxeMJuEyZMaKr1AgDaCOsCqqqqUnZ2thYsWHDGbSZMmKBDhw6Fbi+++OLXWiQAoO2xfuY+Pz9f+fn5Z93G6/UqIyMj4kUBANq+ZnkOaOPGjUpLS1Pfvn1177336ujRo2fctra2VoFAIOwGAGj7mryAJkyYoN/97ndav369Hn/8cRUVFSk/P1+Njad/KW1hYaF8Pl/olpmZ2dRLAgC0QE3+PqBbbrkl9P+DBg3S4MGD1atXL23cuFFjx449ZfvZs2dr1qxZoY8DgQAlBAAXgWZ/GXbPnj2Vmpqq4uLi0z7u9XqVlJQUdgMAtH3NXkAff/yxjh49qi5dujT3rgAArYj1j+COHTsWdjVTUlKinTt3KiUlRSkpKXr00Uc1efJkZWRkaO/evbr//vvVu3dvjR8/vkkXDgBo3awLaPv27Ro9enTo45PP30ydOlXPPPOMdu3apeeff17l5eXy+/0aN26c/u3f/k1er7fpVg0AaPU8xhjjehFfFggE5PP5NEqTFOOJbJBiSxTTxf59UfVZ6daZz/q3s85UZ3isM5J02TV/s85MS99snfm00f55wVhPZINmKxsTrDMZseXWmQ0Vl1pnOsTYDyONZOipJH0zYZ91pjxof+75Yz63zjxQfJN1Jr2d/QBOSfrP7q9ZZ+pN0Dqzu97+H+iJUfZDkSXpj9W9rTMrL+1stX2DqddGrVZFRcVZn9dnFhwAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcaPJfye1Kbf5Q60zaT/8R0b4uS/rYOnNpgv0U6Jqg/TTw+Kh668wHx79hnZGk6mCcdWZPnf1U8IoG+ynL0R77icSSdLgu0Trzy5I868z6YQutMw8enGCdiUqIbNj90cYO1pnJHQIR7Mn+HL+72ybrTM+4w9YZSVpTZf+LNA/Wd7TOpMdWWGd6xH5qnZGkGxP/bp1ZKbtp2OeLKyAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcKLFDiP1xMTI4zn/5eX8/E/W+xib+FfrjCRVG691JpLBopEMNYyEL6Y6olxtvf3pc7g+KaJ92erjLY0od0PSTuvMpqdzrDNX1/zAOrN3zCLrzPrj0dYZSfq0wf7v6ZaSMdaZd/dnWmeu6FFinRmU+Il1RopsEG5idI11JtbTYJ2pCtp/H5KkrTX2g2abC1dAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOBEix1GeujeIYr2xp/39o/4nrLex9LPrrDOSFJm/GfWme5xR6wz2QkfWWcikRhlPzxRkvom2Q9QXFPV1TqzsbyfdaZLbLl1RpL+WN3LOrPskSesM9Nm3medyX3tHutMoEdk/8ZsaG+sM0nZR60zD17+P9aZOE+jdaa80X6oqCSleKusM8nRkQ33tRXJUGRJSow6bp2J7tvbanvTWCvtOfd2XAEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMtdhhpu8NBRccFz3v7NYHLrPfRM+FT64wkHalPtM78/tgg60zXhM+tM75o+0GDvb2l1hlJ2lmTbJ1Z++kA64w/IWCdKav3WWck6Wh9e+tMddB+KORvfjXPOvPLsjzrzA0p71pnJCk7zn6waHnQ/t+zH9RlWGcqg+c/pPikGhNrnZGkigiGmCZG8DVYb+y/FUeb8//++GXJUfbDUgODOllt31BfwzBSAEDLRQEBAJywKqDCwkINHTpUiYmJSktL0/XXX6/du3eHbVNTU6OCggJ16tRJHTp00OTJk1VWVtakiwYAtH5WBVRUVKSCggJt3bpVb7zxhurr6zVu3DhVVX3xS5tmzpypV199VS+//LKKiop08OBB3XjjjU2+cABA62b1zNfatWvDPl68eLHS0tK0Y8cOjRgxQhUVFfrNb36jpUuXasyYMZKkRYsWqX///tq6dauuuCKy30AKAGh7vtZzQBUVFZKklJQUSdKOHTtUX1+vvLwvXq3Tr18/devWTVu2bDnt56itrVUgEAi7AQDavogLKBgMasaMGbrqqqs0cOBASVJpaani4uKUnJwctm16erpKS0//Ut/CwkL5fL7QLTMzM9IlAQBakYgLqKCgQO+//76WLVv2tRYwe/ZsVVRUhG4HDhz4Wp8PANA6RPRG1OnTp2vNmjXatGmTunbtGro/IyNDdXV1Ki8vD7sKKisrU0bG6d9w5vV65fXav5EPANC6WV0BGWM0ffp0rVy5Uhs2bFBWVlbY40OGDFFsbKzWr18fum/37t3av3+/cnNzm2bFAIA2weoKqKCgQEuXLtXq1auVmJgYel7H5/MpISFBPp9Pd9xxh2bNmqWUlBQlJSXpBz/4gXJzc3kFHAAgjFUBPfPMM5KkUaNGhd2/aNEiTZs2TZL0q1/9SlFRUZo8ebJqa2s1fvx4/frXv26SxQIA2g6PMca4XsSXBQIB+Xw+jbj6IcXEnP/QwaHzd1jv6/2A3zojSenxldaZwR0+ts7srrYf1HjweJJ1pl1MvXVGkhKi7XMNxv51L2le++PdzWs/TFOSEqPsB0nGeRqtM40RvP5nQNxB68z+ho7WGUkqbUi2znxQbf/11DHGfjDmXyL4uq1uiLPOSFJto/3T5DUN9hmft8Y6MzTlI+uMJEXJ/lv+0ldGWm0frKnRPx77qSoqKpSUdObvScyCAwA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMR/UbUCyFq8y5FeWLPe/uX/3CV9T4emvSydUaSisr7WWfWlA6yzgTq7H9TbOd2VdaZpFj7adOSlBJrvy9fBNOP4z0N1pnPG9pbZySpNur8z7mTGuWxzpTW+qwzbwUvsc7UB6OtM5JUG0Eukunon9WlWmf8CRXWmcqG85+s/2X7KlOsM0cqOlhnatrZfyve3NjLOiNJEzL+ap1JOGx3jjfWnt/2XAEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMeY4xxvYgvCwQC8vl8GqVJirEYRhqJituuiCjX8/u7rTPDkkusM+8Gulln9kcwPLE+GNm/Q2KjgtaZdrF11pn4CIZcxkU3WmckKUr2Xw7BCIaRto+2Pw7tY2qtM0kxNdYZSUqMts9FeezPh0hER/B3tK2iR9Mv5AwSI/h7ajD2X4O5vr3WGUn6bcmV1hnfNcVW2zeYem3UalVUVCgpKemM23EFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOtNxhpFE32g0jDUY2fPJCqZqcY53J+cmf7DOJ9gMK+8WVWWckKVb2wyfjIxhY2T7KfthnTYSndST/Itt8PNM60xjBnjZ83t86Ux/BkEtJKqs+8wDJM4mNcACsraCxPx+ON0Q22LjieLx1JjrK/tyr2Zhqnen0gf2QXknyvmb/fcUWw0gBAC0aBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJxoucNINcluGCki5hk6KKLc8YwE64z3aK11prK7/X6S9lZZZyQpqrbBOhP8898i2hfQVjGMFADQolFAAAAnrAqosLBQQ4cOVWJiotLS0nT99ddr9+7dYduMGjVKHo8n7HbPPfc06aIBAK2fVQEVFRWpoKBAW7du1RtvvKH6+nqNGzdOVVXhP2+/8847dejQodBt7ty5TbpoAEDrF2Oz8dq1a8M+Xrx4sdLS0rRjxw6NGDEidH+7du2UkZHRNCsEALRJX+s5oIqKCklSSkpK2P1LlixRamqqBg4cqNmzZ6u6uvqMn6O2tlaBQCDsBgBo+6yugL4sGAxqxowZuuqqqzRw4MDQ/d/73vfUvXt3+f1+7dq1Sw888IB2796tFStWnPbzFBYW6tFHH410GQCAViri9wHde++9ev3117V582Z17dr1jNtt2LBBY8eOVXFxsXr16nXK47W1taqt/eK9IYFAQJmZmbwP6ALifUBf4H1AwNd3vu8DiugKaPr06VqzZo02bdp01vKRpJycHEk6YwF5vV55vd5IlgEAaMWsCsgYox/84AdauXKlNm7cqKysrHNmdu7cKUnq0qVLRAsEALRNVgVUUFCgpUuXavXq1UpMTFRpaakkyefzKSEhQXv37tXSpUt1zTXXqFOnTtq1a5dmzpypESNGaPDgwc3yBwAAtE5WBfTMM89IOvFm0y9btGiRpk2bpri4OK1bt07z589XVVWVMjMzNXnyZD344INNtmAAQNtg/SO4s8nMzFRRUdHXWhAA4OIQ8cuw0XaYP/0lolx8E6/jTJLevkA7khS8cLsCLnoMIwUAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHAixvUCvsoYI0lqUL1kHC8GAGCtQfWSvvh+fiYtroAqKyslSZv1muOVAAC+jsrKSvl8vjM+7jHnqqgLLBgM6uDBg0pMTJTH4wl7LBAIKDMzUwcOHFBSUpKjFbrHcTiB43ACx+EEjsMJLeE4GGNUWVkpv9+vqKgzP9PT4q6AoqKi1LVr17Nuk5SUdFGfYCdxHE7gOJzAcTiB43CC6+Nwtiufk3gRAgDACQoIAOBEqyogr9erOXPmyOv1ul6KUxyHEzgOJ3AcTuA4nNCajkOLexECAODi0KqugAAAbQcFBABwggICADhBAQEAnKCAAABOtJoCWrBggXr06KH4+Hjl5ORo27Ztrpd0wT3yyCPyeDxht379+rleVrPbtGmTJk6cKL/fL4/Ho1WrVoU9bozRww8/rC5duighIUF5eXnas2ePm8U2o3Mdh2nTpp1yfkyYMMHNYptJYWGhhg4dqsTERKWlpen666/X7t27w7apqalRQUGBOnXqpA4dOmjy5MkqKytztOLmcT7HYdSoUaecD/fcc4+jFZ9eqyigl156SbNmzdKcOXP07rvvKjs7W+PHj9fhw4ddL+2CGzBggA4dOhS6bd682fWSml1VVZWys7O1YMGC0z4+d+5cPfnkk1q4cKHeeecdtW/fXuPHj1dNTc0FXmnzOtdxkKQJEyaEnR8vvvjiBVxh8ysqKlJBQYG2bt2qN954Q/X19Ro3bpyqqqpC28ycOVOvvvqqXn75ZRUVFengwYO68cYbHa666Z3PcZCkO++8M+x8mDt3rqMVn4FpBYYNG2YKCgpCHzc2Nhq/328KCwsdrurCmzNnjsnOzna9DKckmZUrV4Y+DgaDJiMjwzzxxBOh+8rLy43X6zUvvviigxVeGF89DsYYM3XqVDNp0iQn63Hl8OHDRpIpKioyxpz4u4+NjTUvv/xyaJu//e1vRpLZsmWLq2U2u68eB2OMGTlypPnRj37kblHnocVfAdXV1WnHjh3Ky8sL3RcVFaW8vDxt2bLF4crc2LNnj/x+v3r27KnbbrtN+/fvd70kp0pKSlRaWhp2fvh8PuXk5FyU58fGjRuVlpamvn376t5779XRo0ddL6lZVVRUSJJSUlIkSTt27FB9fX3Y+dCvXz9169atTZ8PXz0OJy1ZskSpqakaOHCgZs+ererqahfLO6MWNw37q44cOaLGxkalp6eH3Z+enq4PP/zQ0arcyMnJ0eLFi9W3b18dOnRIjz76qIYPH673339fiYmJrpfnRGlpqSSd9vw4+djFYsKECbrxxhuVlZWlvXv36ic/+Yny8/O1ZcsWRUdHu15ekwsGg5oxY4auuuoqDRw4UNKJ8yEuLk7Jyclh27bl8+F0x0GSvve976l79+7y+/3atWuXHnjgAe3evVsrVqxwuNpwLb6A8IX8/PzQ/w8ePFg5OTnq3r27li9frjvuuMPhytAS3HLLLaH/HzRokAYPHqxevXpp48aNGjt2rMOVNY+CggK9//77F8XzoGdzpuNw1113hf5/0KBB6tKli8aOHau9e/eqV69eF3qZp9XifwSXmpqq6OjoU17FUlZWpoyMDEerahmSk5PVp08fFRcXu16KMyfPAc6PU/Xs2VOpqalt8vyYPn261qxZozfffDPs94dlZGSorq5O5eXlYdu31fPhTMfhdHJyciSpRZ0PLb6A4uLiNGTIEK1fvz50XzAY1Pr165Wbm+twZe4dO3ZMe/fuVZcuXVwvxZmsrCxlZGSEnR+BQEDvvPPORX9+fPzxxzp69GibOj+MMZo+fbpWrlypDRs2KCsrK+zxIUOGKDY2Nux82L17t/bv39+mzodzHYfT2blzpyS1rPPB9asgzseyZcuM1+s1ixcvNh988IG56667THJysiktLXW9tAvqvvvuMxs3bjQlJSXmrbfeMnl5eSY1NdUcPnzY9dKaVWVlpXnvvffMe++9ZySZefPmmffee8989NFHxhhj/v3f/90kJyeb1atXm127dplJkyaZrKwsc/z4cccrb1pnOw6VlZXmxz/+sdmyZYspKSkx69atM9/85jfNJZdcYmpqalwvvcnce++9xufzmY0bN5pDhw6FbtXV1aFt7rnnHtOtWzezYcMGs337dpObm2tyc3Mdrrrpnes4FBcXm5/97Gdm+/btpqSkxKxevdr07NnTjBgxwvHKw7WKAjLGmKeeesp069bNxMXFmWHDhpmtW7e6XtIFN2XKFNOlSxcTFxdnvvGNb5gpU6aY4uJi18tqdm+++aaRdMpt6tSpxpgTL8V+6KGHTHp6uvF6vWbs2LFm9+7dbhfdDM52HKqrq824ceNM586dTWxsrOnevbu5884729w/0k7355dkFi1aFNrm+PHj5vvf/77p2LGjadeunbnhhhvMoUOH3C26GZzrOOzfv9+MGDHCpKSkGK/Xa3r37m3+9V//1VRUVLhd+Ffw+4AAAE60+OeAAABtEwUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOPH/AJwzvDRHMohYAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "image, label = train_data[0]\n",
        "print(f\"image shape: {image.shape}\")\n",
        "plt.imshow(image.squeeze())\n",
        "plt.title(class_names[label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9d6c9780-09c0-4b78-936c-189e8b4c449c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "9d6c9780-09c0-4b78-936c-189e8b4c449c",
        "outputId": "4f315477-3cac-4aa3-9663-88eb0e76bb1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.5, 27.5, 27.5, -0.5)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[label])\n",
        "plt.axis(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "394ca12d-c05b-4629-a032-afc47aa3283e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "394ca12d-c05b-4629-a032-afc47aa3283e",
        "outputId": "d7667feb-98b0-4268-8fa4-ab578fc65697"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x900 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# plot more images\n",
        "#torch.manual_seed(42)\n",
        "fig = plt.figure(figsize=(9,9))\n",
        "rows, cols = 4,4\n",
        "for i in range(1, rows*cols +1):\n",
        "    random_idx = torch.randint(0,len(train_data), size=[1]).item()\n",
        "    img,label = train_data[random_idx]\n",
        "    fig.add_subplot(rows,cols,i)\n",
        "    plt.imshow(img.squeeze(),cmap=\"gray\")\n",
        "    plt.title(class_names[label])\n",
        "    plt.axis(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dfc7dbe-acbc-4a71-9a92-2960f124fe65",
      "metadata": {
        "id": "6dfc7dbe-acbc-4a71-9a92-2960f124fe65"
      },
      "source": [
        "## 2. Dataloader overview and understanding mini batches\n",
        "[Chapter 98](https://youtu.be/V_xro1bcAuA&t=54094)\n",
        "\n",
        "Prepare dataloader\n",
        "\n",
        "Right now our data is in the form of a pytorch dataset.\n",
        "Specifically we want to turn our data into batches (or mini-batches).\n",
        "We have a relatively small train dataset but in case we split it into batches for example 32 images at a time. Doing so allows the network to update gradients multiple times per epoch.\n",
        "\n",
        "The other reason is efficiency and memory  available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ea9763b8-b6df-44d6-b631-2b58cea3ba39",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea9763b8-b6df-44d6-b631-2b58cea3ba39",
        "outputId": "1ab33321-0466-4617-cfac-b2017120fe75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset FashionMNIST\n",
              "     Number of datapoints: 60000\n",
              "     Root location: data\n",
              "     Split: Train\n",
              "     StandardTransform\n",
              " Transform: ToTensor(),\n",
              " Dataset FashionMNIST\n",
              "     Number of datapoints: 10000\n",
              "     Root location: data\n",
              "     Split: Test\n",
              "     StandardTransform\n",
              " Transform: ToTensor())"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "train_data, test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4e0b449d-b59a-4931-b624-cbac45ef11eb",
      "metadata": {
        "id": "4e0b449d-b59a-4931-b624-cbac45ef11eb"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                     batch_size=BATCH_SIZE,\n",
        "                     shuffle=True) # provides more randomness per batch\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                     batch_size=BATCH_SIZE,\n",
        "                     shuffle=False) # no real need to shuffle test data\n",
        "\n",
        "#  train_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "418c7cdf-0efe-4925-9d01-e2241b239c23",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "418c7cdf-0efe-4925-9d01-e2241b239c23",
        "outputId": "1ec14f55-1416-42d1-e599-b4ce7c8c4ad5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataLoaders:\n",
            "   Train: <torch.utils.data.dataloader.DataLoader object at 0x78609c3be110>,\n",
            "   Test: <torch.utils.data.dataloader.DataLoader object at 0x78609c3bdab0> \n",
            "Length of train_dataloader: 938 batches of 64 \n",
            "Length of test_dataloader: 157 batches of 64 \n"
          ]
        }
      ],
      "source": [
        "# What did we just create?\n",
        "print(f\"DataLoaders:\\n   Train: {train_dataloader},\\n   Test: {test_dataloader} \")\n",
        "print(f\"Length of train_dataloader: {len(train_dataloader)} batches of {BATCH_SIZE} \")\n",
        "print(f\"Length of test_dataloader: {len(test_dataloader)} batches of {BATCH_SIZE} \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "66d6e3b3-a1f8-426f-9c55-71e2d2b7d550",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66d6e3b3-a1f8-426f-9c55-71e2d2b7d550",
        "outputId": "7fd7aac5-b122-4f0b-b327-ee18e0d507f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Check out what is inside training dataloader\n",
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
        "train_features_batch.shape, train_labels_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "109a45a9-b83f-4a0e-9876-775ae08b9b8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "109a45a9-b83f-4a0e-9876-775ae08b9b8d",
        "outputId": "0745e8fe-f06c-4394-e98b-64fb5a81cedf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size: torch.Size([1, 28, 28])\n",
            "Label: 4, size: torch.Size([])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Show a sample\n",
        "#torch.manual_seed(42)\n",
        "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
        "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[label])\n",
        "plt.axis(False)\n",
        "print(f\"Image size: {img.shape}\")\n",
        "print(f\"Label: {label}, size: {label.shape}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e11704f8-00b9-4b5b-aae3-87360b624c11",
      "metadata": {
        "id": "e11704f8-00b9-4b5b-aae3-87360b624c11"
      },
      "source": [
        "## 3.  Model 0: Creating a baseline with 2 linear layers | [chapter 100](https://youtu.be/V_xro1bcAuA&t=55277)\n",
        "A base model is a simple model which you will try to improve upon with subsequent models/experiments.  \n",
        "**MAKE REVISIONS:**  rather than overwritting previous models, create new models with added complexity step by step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "76d26a6b-6eb2-44c9-885e-53df0adbaedf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76d26a6b-6eb2-44c9-885e-53df0adbaedf",
        "outputId": "2509ca5e-c936-46de-b88c-82ed002aac53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape before flattening: torch.Size([1, 28, 28])\n",
            "Shape after flattening: torch.Size([1, 784])\n"
          ]
        }
      ],
      "source": [
        "# Create a flatten layer\n",
        "# This will create a flat version of our 28,28 matrix into a single [1,28*28] tensor\n",
        "\n",
        "flatten_model = nn.Flatten()\n",
        "# Get a single sample\n",
        "x = train_features_batch[0]\n",
        "x_flat = flatten_model(x)\n",
        "\n",
        "print(f\"Shape before flattening: {x.shape}\")\n",
        "print(f\"Shape after flattening: {x_flat.shape}\")\n",
        "\n",
        "# we want to send this to a linear layer that can opnly handle a single layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "6a8f1617-61e3-4780-8d12-9da1a672f732",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6a8f1617-61e3-4780-8d12-9da1a672f732",
        "outputId": "d85a0fe9-dd64-4715-898a-f9830e3322a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# We need device agnostic code\n",
        "#device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device=\"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "0d4b30d5-2045-463f-b3a4-45ae2c40a7ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d4b30d5-2045-463f-b3a4-45ae2c40a7ce",
        "outputId": "82c8f893-04fb-4977-ffbb-091dec3d93ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionMNISTModel_V0(\n",
              "  (layer_stack): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=784, out_features=16, bias=True)\n",
              "    (2): Linear(in_features=16, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "IN_SHAPE = 784  #28*28 flattened image\n",
        "OUT_SHAPE = len(class_names)\n",
        "HIDDEN_UNITS = 16  # magic number to play with\n",
        "\n",
        "from torch import nn\n",
        "class FashionMNISTModel_V0(nn.Module):\n",
        "    def __init__(self,\n",
        "                input_shape: int,\n",
        "                hidden_shape: int,\n",
        "                output_shape: int):\n",
        "        super().__init__()\n",
        "        self.layer_stack= nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=input_shape,\n",
        "                     out_features=hidden_shape),\n",
        "\n",
        "            nn.Linear(in_features=hidden_shape,\n",
        "                     out_features=output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.layer_stack(x)\n",
        "\n",
        "# setup model with my HParam\n",
        "model_0 = FashionMNISTModel_V0(IN_SHAPE, HIDDEN_UNITS, OUT_SHAPE).to(device)\n",
        "model_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "52b60494-f0ae-46ad-a13a-a6be81e41cc1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52b60494-f0ae-46ad-a13a-a6be81e41cc1",
        "outputId": "3d0b72b0-f5a7-4f94-c30a-7466d22f0898"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0991, 0.0891, 0.0776, 0.1015, 0.1622, 0.1011, 0.0925, 0.0579, 0.1193,\n",
              "          0.0996]], grad_fn=<SoftmaxBackward0>),\n",
              " 4)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "dummy_x = torch.rand([1,1,28,28]).to(device)\n",
        "logit = model_0(dummy_x)\n",
        "dummy_probs = torch.softmax(logit,dim=1)\n",
        "#.argmax(dim=1)\n",
        "dummy_pred = torch.argmax(dummy_probs, dim=1)\n",
        "dummy_probs, dummy_pred.item()\n",
        "#correct = torch.eq(y_true, y_pred).sum().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "907d69a5-8312-45f0-959d-cc7ef3c80988",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "907d69a5-8312-45f0-959d-cc7ef3c80988",
        "outputId": "7df7ade4-e0d4-43e1-99b6-1646ad9c45a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('layer_stack.1.weight',\n",
              "              tensor([[-0.0078,  0.0072, -0.0174,  ..., -0.0354,  0.0187,  0.0085],\n",
              "                      [-0.0182,  0.0344, -0.0162,  ...,  0.0017,  0.0045,  0.0133],\n",
              "                      [-0.0108, -0.0213,  0.0084,  ...,  0.0273, -0.0081,  0.0026],\n",
              "                      ...,\n",
              "                      [ 0.0327,  0.0125, -0.0200,  ..., -0.0315, -0.0168, -0.0187],\n",
              "                      [-0.0337,  0.0056, -0.0028,  ..., -0.0167, -0.0028, -0.0070],\n",
              "                      [ 0.0241,  0.0167,  0.0275,  ...,  0.0289,  0.0107,  0.0284]])),\n",
              "             ('layer_stack.1.bias',\n",
              "              tensor([-0.0170, -0.0234, -0.0287, -0.0056, -0.0035, -0.0203, -0.0122, -0.0115,\n",
              "                       0.0344, -0.0026,  0.0290,  0.0034,  0.0127,  0.0206, -0.0329, -0.0161])),\n",
              "             ('layer_stack.2.weight',\n",
              "              tensor([[-0.1900,  0.2429,  0.0917, -0.1048, -0.1885,  0.1384,  0.0580, -0.1230,\n",
              "                       -0.1814, -0.1305,  0.0609, -0.2105, -0.0264,  0.1484,  0.1335,  0.0270],\n",
              "                      [ 0.0266,  0.0584,  0.0976,  0.1973,  0.0679,  0.1374,  0.1743, -0.1939,\n",
              "                       -0.1334,  0.1373,  0.0501, -0.1443,  0.0739, -0.2273, -0.0930,  0.1261],\n",
              "                      [-0.0066, -0.1689,  0.1236,  0.0174, -0.0358, -0.2404, -0.0902,  0.0276,\n",
              "                       -0.1359,  0.0421, -0.1776,  0.1929,  0.1925,  0.1473, -0.0297, -0.2491],\n",
              "                      [-0.0976, -0.0203, -0.2304,  0.1968,  0.0712,  0.1897, -0.2237, -0.1284,\n",
              "                        0.0563, -0.0038, -0.1454,  0.1828,  0.1031, -0.0119,  0.2382, -0.2438],\n",
              "                      [-0.2271,  0.0499,  0.2269,  0.1413, -0.1376,  0.1794,  0.1299,  0.0142,\n",
              "                        0.1582,  0.0495,  0.0003, -0.0692, -0.1328, -0.1576, -0.0329, -0.1710],\n",
              "                      [ 0.1060,  0.0706, -0.2437, -0.1839,  0.1787, -0.1311, -0.0026, -0.1601,\n",
              "                       -0.0547,  0.1233,  0.0635,  0.1227, -0.0146, -0.1995, -0.0031,  0.1482],\n",
              "                      [ 0.0585,  0.0517,  0.0492,  0.2051,  0.1261, -0.0409, -0.1356,  0.2034,\n",
              "                       -0.1301, -0.1671,  0.0781, -0.1596, -0.2157, -0.2024,  0.0616, -0.1571],\n",
              "                      [ 0.2212, -0.0100, -0.1062, -0.1533, -0.0747,  0.2181, -0.1596, -0.2315,\n",
              "                        0.0744,  0.0848, -0.2118, -0.1122,  0.2167, -0.1182,  0.1049, -0.1200],\n",
              "                      [-0.2207, -0.2412,  0.1907,  0.0766,  0.0711,  0.0860,  0.0963,  0.1650,\n",
              "                        0.1918,  0.1928,  0.0803,  0.0446,  0.0537, -0.2025,  0.1115,  0.0617],\n",
              "                      [ 0.1087, -0.0617,  0.2076,  0.0300, -0.0593, -0.0071, -0.0998, -0.0367,\n",
              "                        0.2122,  0.0829, -0.0279,  0.0094,  0.0571, -0.1443, -0.1371,  0.2204]])),\n",
              "             ('layer_stack.2.bias',\n",
              "              tensor([ 0.0014,  0.0744, -0.1150, -0.1838,  0.0496,  0.1350, -0.2355, -0.2473,\n",
              "                      -0.0834,  0.1617]))])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "#101 15,35,57\n",
        "model_0.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "9d5b1517-019a-4524-ae28-25645e8797f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d5b1517-019a-4524-ae28-25645e8797f4",
        "outputId": "836433df-5ac9-4263-adac-0669c5dc10b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading helper_functions.py\n"
          ]
        }
      ],
      "source": [
        "# a nice little tidbit to check and load additional files\n",
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "#  download file if needed\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "      print(\"helper_functions.py already exists, skipping download\")\n",
        "else:\n",
        "  print(\"Downloading helper_functions.py\")\n",
        "  # Note: you need the \"raw\" GitHub URL for this to work\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "efe33fe4-d15c-4068-be54-a8633c357c5f",
      "metadata": {
        "id": "efe33fe4-d15c-4068-be54-a8633c357c5f"
      },
      "outputs": [],
      "source": [
        "from helper_functions import accuracy_fn\n",
        "\n",
        "# set up loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
        "                           lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "912098f7-4b74-4a6f-9c8b-edf7d07cdd5e",
      "metadata": {
        "id": "912098f7-4b74-4a6f-9c8b-edf7d07cdd5e"
      },
      "source": [
        "### 3.2 Creating a function to time our experiments |  [chapter 102](https://youtu.be/V_xro1bcAuA&t=56787)\n",
        "\n",
        "Machine learning is very experimental\n",
        "\n",
        "Two of the main things you'll want to track are:\n",
        "1. Model's performance (loss accuracy values etc)\n",
        "2. How fast it runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "151cd8bf-2400-49c2-89db-271bc49cd0b6",
      "metadata": {
        "id": "151cd8bf-2400-49c2-89db-271bc49cd0b6"
      },
      "outputs": [],
      "source": [
        "from timeit import default_timer as timer\n",
        "def print_train_time(start: float,\n",
        "                     stop: float,\n",
        "                     device: torch.device = None):\n",
        "    \"\"\" Prints difference between start and stop times\n",
        "    return: The time in millseconds of runtime\n",
        "    \"\"\"\n",
        "    total_time_ms = (stop - start) * 1000\n",
        "    print(f\"Train time on device {device}: {total_time_ms:.3f} milliseconds\")\n",
        "    return total_time_ms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "63d3ac39-cb60-4d5a-bb5e-bd41a06f9e56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63d3ac39-cb60-4d5a-bb5e-bd41a06f9e56",
        "outputId": "b912fa82-0161-4f00-f362-ef6d8a47184a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train time on device cuda: 0.038 milliseconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03764300004149845"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "start_time = timer()\n",
        "# some code\n",
        "stop_time = timer()\n",
        "print_train_time(start_time, stop_time, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "5ea372d9-1ce1-46ca-b3bd-d8c1344bfdfc",
      "metadata": {
        "id": "5ea372d9-1ce1-46ca-b3bd-d8c1344bfdfc"
      },
      "outputs": [],
      "source": [
        "# better Timer than above\n",
        "import time\n",
        "\n",
        "class Timer():\n",
        "    def __init__(self,dev :str = \"unspecified\"):\n",
        "        self.device = dev\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.start_time = time.time()  # Take the initial snapshot of time\n",
        "\n",
        "        return self  # Return the instance for optional use in the `with` block\n",
        "\n",
        "    def __exit__(self, exc_type, exc_value, traceback):\n",
        "        self.end_time = time.time()  # Take the snapshot of time when exiting the context\n",
        "        self.elapsed_time = self.end_time - self.start_time  # Calculate elapsed time\n",
        "        print(f\"Elapsed time on {self.device} device: {self.elapsed_time:.4f} seconds\")\n",
        "        # If needed, handle exceptions (return False to propagate exceptions)\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "13075f1b-bb28-4126-8199-d0d82c50e23a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13075f1b-bb28-4126-8199-d0d82c50e23a",
        "outputId": "bf863bc0-896e-44ae-aa6c-81ebfea39675"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time on unspecified device: 0.0002 seconds\n",
            "Timed out of loop: 0.00017261505126953125\n"
          ]
        }
      ],
      "source": [
        "with Timer() as t:\n",
        "    for i in range(1,1000):\n",
        "        if i% 1000 == 0:\n",
        "            pass\n",
        "\n",
        "print(f\"Timed out of loop: {t.elapsed_time}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01367674-fe13-4061-a9a7-8cce9ddc92f4",
      "metadata": {
        "id": "01367674-fe13-4061-a9a7-8cce9ddc92f4"
      },
      "source": [
        "### 3.3 Creating a training loop for batched data |  [chapter 103](https://youtu.be/V_xro1bcAuA&t=57121)\n",
        "**Note:** the optimizer will update model's parameters once per batch ... i.e. Many times per epoch\n",
        "1. Loop through epochs\n",
        "2. Loop thru training batches, perform training steps, calculate the train loss per batch\n",
        "3. Loop thru testing batches, perform test steps, calculate the loss per batch\n",
        "4. Print out whats' happinin'\n",
        "5. Time it all (for fun)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "79c876d8-a8bf-478a-a1bc-c6d86ed0fd2c",
      "metadata": {
        "id": "79c876d8-a8bf-478a-a1bc-c6d86ed0fd2c"
      },
      "outputs": [],
      "source": [
        "# assumption is all preparations have been made cuz the timer is running\n",
        "def train_loop(epochs: int):\n",
        "    # create\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        print(f\"epoch: {epoch}\\n----\")\n",
        "        #Training\n",
        "        train_loss = 0 # add all batch losses, divide by num batches to get average epoch loss\n",
        "        #add a loop to loop thru batches\n",
        "        for batch, (X,targets) in enumerate(train_dataloader):\n",
        "            model_0.train()\n",
        "            # 1. forward pass\n",
        "            train_logits = model_0(X)\n",
        "            train_probs = torch.softmax(train_logits,dim=1)\n",
        "            #.argmax(dim=1)\n",
        "            train_preds = torch.argmax(train_probs, dim=1)\n",
        "            # 2. Calculate the loss (per Batch)\n",
        "            loss = loss_fn(train_logits, targets)\n",
        "            train_loss += loss\n",
        "            # last 3  basic steps\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            # step what params\n",
        "            optimizer.step()\n",
        "\n",
        "            #print\n",
        "            if batch % 400 == 0:\n",
        "                print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
        "        # Divide total train loss by length of train dataloader\n",
        "        train_loss /= len(train_dataloader) # num of batches\n",
        "\n",
        "        # Testing\n",
        "        test_loss, test_acc = 0, 0\n",
        "        model_0.eval()\n",
        "        with torch.inference_mode():\n",
        "            for X_test, test_targets in test_dataloader:  # test batches\n",
        "                # 1. forward pass\n",
        "                test_logits = model_0(X_test)\n",
        "\n",
        "                # 2. Calculate the loss (per Batch)\n",
        "                test_loss = loss_fn(test_logits, test_targets)\n",
        "                # last 3 - 5 training steps not needed in test loop\n",
        "\n",
        "                # Calculate accuracy\n",
        "                # Accuracy needs labels to labels\n",
        "                test_preds = torch.softmax(test_logits,dim=1).argmax(dim=1)\n",
        "                test_acc += accuracy_fn(y_true=test_targets,\n",
        "                                       y_pred= test_preds)\n",
        "\n",
        "            # Calculate test loss average per batch\n",
        "            test_loss /= len(test_dataloader)\n",
        "            # calculate the acc average per batch\n",
        "            test_acc /=len(test_dataloader)\n",
        "\n",
        "        # Print out whats' happinin'\n",
        "        #print(f\"EPOCH: {epoch} | Loss: {train_loss:.4f}, Acc: {acc:.2f}%  | Test loss: {test_loss:.5f}, acc: {test_acc:.2f}%\")\n",
        "        print(f\"EPOCH: {epoch} | Loss: {train_loss:.4f}  | Test loss: {test_loss:.5f}, acc: {test_acc:.2f}%\")\n",
        "\n",
        "    # Calculate train time\n",
        "    #  My class handles this automatically"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "dacd30cd-55c0-44df-ba59-892830d8b8fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "d8fdd67508414dd29c08de4e8f12ef32",
            "01378f090bd546e48d401732965f5067",
            "431d7b29c7994a3298a2e0d679ebe4de",
            "2e61be13483c42d29bbe600668606025",
            "9762961383b84f23b8e0e3246c664d03",
            "053d77aea0c448e1a0931604588aa3d1",
            "63172b8fa9ea4744869dfd7d461bc6d3",
            "82f94f3b8c9c4dd58d209fa793302173",
            "9f3a8bd909584485a6464e91266f060b",
            "c0ccaf288eb548e09ab4b1f08e73af4c",
            "84c135108f024f0b8d437443847cb9f7"
          ]
        },
        "id": "dacd30cd-55c0-44df-ba59-892830d8b8fe",
        "outputId": "9a067d5a-a628-41b6-9ed6-395458d30984"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8fdd67508414dd29c08de4e8f12ef32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\n",
            "----\n",
            "Looked at 0/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 51200/60000 samples\n",
            "EPOCH: 0 | Loss: 0.4409  | Test loss: 0.00197, acc: 83.50%\n",
            "epoch: 1\n",
            "----\n",
            "Looked at 0/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 51200/60000 samples\n",
            "EPOCH: 1 | Loss: 0.4336  | Test loss: 0.00185, acc: 82.10%\n",
            "epoch: 2\n",
            "----\n",
            "Looked at 0/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 51200/60000 samples\n",
            "EPOCH: 2 | Loss: 0.4254  | Test loss: 0.00227, acc: 83.69%\n",
            "Elapsed time on cpu device: 25.0134 seconds\n"
          ]
        }
      ],
      "source": [
        "# Import tqdm for progress bar\n",
        "from tqdm.auto import tqdm\n",
        "# set seed and start timer\n",
        "torch.manual_seed(42)\n",
        "# set epochs small for faster training time\n",
        "epochs = 3\n",
        "with Timer(device) as timer: #optional parameter for listing device used\n",
        "    train_loop(epochs)\n",
        "total_train_time_model_0 = timer.elapsed_time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6b6732a-c7f6-4fa3-b77f-3949a6430170",
      "metadata": {
        "id": "e6b6732a-c7f6-4fa3-b77f-3949a6430170"
      },
      "source": [
        "## 4. Make prediction and get model_0 results  \n",
        "[Chapter 104](https://youtu.be/V_xro1bcAuA&t=58696)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "491db210-8138-47d5-83e9-9da580b15dcf",
      "metadata": {
        "id": "491db210-8138-47d5-83e9-9da580b15dcf"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "def eval_model(model:nn.Module,\n",
        "              data_loader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              accuracy_fn,\n",
        "              device = 'cpu'):\n",
        "    \"\"\"Returns a dictionary containing the results of model predicting on data_loader.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.\n",
        "        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.\n",
        "        loss_fn (torch.nn.Module): The loss function of model.\n",
        "        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.\n",
        "\n",
        "    Returns:\n",
        "        (dict): Results of model making predictions on data_loader.\n",
        "    \"\"\"\n",
        "    loss, acc = 0, 0\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in tqdm(data_loader):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            # Make predictions\n",
        "            y_pred = model(X)\n",
        "\n",
        "            # Accumulate the loss and acc values per batch\n",
        "            loss += loss_fn(y_pred, y)\n",
        "             # For accuracy, need the prediction labels (logits -> pred_prob -> pred_labels)\n",
        "            acc += accuracy_fn(y_true=y,\n",
        "                              y_pred=y_pred.argmax(dim=1))\n",
        "\n",
        "        # Scale loss and acc to get the average per batch\n",
        "        loss /= len(data_loader)\n",
        "        acc /= len(data_loader)\n",
        "\n",
        "\n",
        "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
        "            \"model_loss\": loss.item(),\n",
        "            \"model_acc\": acc,\n",
        "            \"device\" : device }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "ef07da9e-d74f-4cad-8d5b-f259a1c14d1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "81aa75b793bd4b64b4782d4b36441d9a",
            "752ebac5c0024e86a179767f1eb0892b",
            "2290fa4c51bc4fcaa95b462832e9fde7",
            "e2f7d4f2a04f4ed4b6e5a7001c99807d",
            "6541cbe564504e15bef9f2a436a05bc1",
            "a0f9d6edde734dc5970954bb5460a0d3",
            "2f38f3f3bc564ebf92a35775e0d7b8c6",
            "ae6ac5549f054948bd3b6801649b352c",
            "2f3dfe0ae8e947e59d08250f28bf402f",
            "84fa1b5c24404feb8d99b6d93c748f4b",
            "c29b6b5497a3439fb0e6cf5faa155d2b"
          ]
        },
        "id": "ef07da9e-d74f-4cad-8d5b-f259a1c14d1c",
        "outputId": "678ef7f5-fdb9-44d2-ca86-252287717a2b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/157 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81aa75b793bd4b64b4782d4b36441d9a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_name': 'FashionMNISTModel_V0',\n",
              " 'model_loss': 0.47066444158554077,\n",
              " 'model_acc': 83.68829617834395,\n",
              " 'device': 'cpu'}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# Calculate model_0 results on test dataset\n",
        "# note: loss function should be CrossEntropy for this model\n",
        "model_0_results = eval_model(model=model_0, data_loader=test_dataloader,\n",
        "                            loss_fn=loss_fn, accuracy_fn=accuracy_fn\n",
        ")\n",
        "model_0_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35e34297-29f4-4e00-b86f-d185b9080496",
      "metadata": {
        "id": "35e34297-29f4-4e00-b86f-d185b9080496"
      },
      "source": [
        "## 5. Setup device-agnostic code\n",
        "\n",
        "[chapter 105](https://youtu.be/V_xro1bcAuA&t=59187)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "ab6d8c3d-c88f-48c9-b94a-b831ddcd6cb4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ab6d8c3d-c88f-48c9-b94a-b831ddcd6cb4",
        "outputId": "a19226c0-2802-4b4c-8c15-a8bba454a76d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# We need device agnistic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "#device=\"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ddf9a24-a943-44d2-8a84-b11852fc520e",
      "metadata": {
        "id": "2ddf9a24-a943-44d2-8a84-b11852fc520e"
      },
      "source": [
        "## 6. Building a better model with non-linearity\n",
        "[chapter 106](https://youtu.be/V_xro1bcAuA&t=59415)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "f0392cc8-c407-4554-9581-90f891fffd93",
      "metadata": {
        "id": "f0392cc8-c407-4554-9581-90f891fffd93"
      },
      "outputs": [],
      "source": [
        "IN_SHAPE = 784  #28*28 flattened image\n",
        "OUT_SHAPE = len(class_names)\n",
        "HIDDEN_UNITS = 16  # magic number to play with\n",
        "\n",
        "from torch import nn\n",
        "class FashionMNISTModel_V1(nn.Module):\n",
        "    def __init__(self,\n",
        "                input_shape: int,\n",
        "                hidden_shape: int,\n",
        "                output_shape: int):\n",
        "        super().__init__()\n",
        "        self.layer_stack= nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=input_shape,\n",
        "                     out_features=hidden_shape),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(in_features=hidden_shape,\n",
        "                     out_features=hidden_shape),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(in_features=hidden_shape,\n",
        "                     out_features=output_shape),\n",
        "            nn.ReLU()\n",
        "\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.layer_stack(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "0b2bf659-837d-4f11-a830-a126e6895130",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b2bf659-837d-4f11-a830-a126e6895130",
        "outputId": "9cc9ac53-97a2-440a-d850-29f3a2ae3c73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionMNISTModel_V1(\n",
              "  (layer_stack): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=784, out_features=16, bias=True)\n",
              "    (2): Sigmoid()\n",
              "    (3): Linear(in_features=16, out_features=16, bias=True)\n",
              "    (4): Sigmoid()\n",
              "    (5): Linear(in_features=16, out_features=10, bias=True)\n",
              "    (6): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "# setup model with my HParam\n",
        "model_1 = FashionMNISTModel_V1(IN_SHAPE, HIDDEN_UNITS, OUT_SHAPE)\n",
        "model_1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44bb5a33-4092-4154-ab49-803ef1c087dd",
      "metadata": {
        "id": "44bb5a33-4092-4154-ab49-803ef1c087dd"
      },
      "source": [
        "### 6.1 Setup loss, optimizer and evaluation metrics |[chapter 107](https://youtu.be/V_xro1bcAuA&t=59958)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "71691dd2-86ea-417f-be3a-f365c3140164",
      "metadata": {
        "id": "71691dd2-86ea-417f-be3a-f365c3140164"
      },
      "outputs": [],
      "source": [
        "from helper_functions import accuracy_fn\n",
        "\n",
        "# set up loss and optimizer\n",
        "loss_fn_1 = nn.CrossEntropyLoss()\n",
        "optimizer_1 = torch.optim.SGD(params=model_1.parameters(),\n",
        "                           lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "304d97b2-f0f2-4bc4-b666-ac01c780f2a2",
      "metadata": {
        "id": "304d97b2-f0f2-4bc4-b666-ac01c780f2a2"
      },
      "source": [
        "### 6.2 functionalizing train, test loops\n",
        "[chapter 108](https://youtu.be/V_xro1bcAuA&t=60143)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "abb9fd48-9f8b-40bd-b422-fe6a4689737a",
      "metadata": {
        "id": "abb9fd48-9f8b-40bd-b422-fe6a4689737a"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Training loop function\n",
        "\"\"\"\n",
        "def train_step(model:nn.Module,\n",
        "                data_loader: torch.utils.data.DataLoader,\n",
        "                loss_fn: nn.Module,\n",
        "                optimizer: torch.optim.Optimizer,\n",
        "                accuracy_fn,\n",
        "                device: torch.device = device\n",
        "              ):\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    # get all data  on device\n",
        "    model.to(device)\n",
        "\n",
        "    for batch, (X,targets) in enumerate(data_loader):\n",
        "        X ,targets = X.to(device), targets.to(device)\n",
        "\n",
        "        model.train()\n",
        "        # 1. forward pass\n",
        "        train_pred = model(X)\n",
        "\n",
        "        # 2. Calculate the loss (per Batch)\n",
        "        loss = loss_fn(train_pred, targets)\n",
        "        train_loss += loss\n",
        "        train_acc += accuracy_fn(y_true=targets,\n",
        "                                 y_pred= train_pred.argmax(dim=1))\n",
        "\n",
        "\n",
        "        # Optimizer.zero_grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "    # Divide total train loss and accuracy by length of number of batches\n",
        "    train_loss /= len(data_loader)\n",
        "    train_acc /= len(data_loader)\n",
        "    print(f\"Train Loss: {train_loss:.4f}  | Train accuracy: {train_acc:.2f}%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a3e8746-d361-4575-a221-193febb8812d",
      "metadata": {
        "id": "6a3e8746-d361-4575-a221-193febb8812d"
      },
      "source": [
        "### 6.3 functionalizing test loops\n",
        "[chapter 109](https://youtu.be/V_xro1bcAuA&t=60653)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "3933954a-9274-4ea5-8ab3-53b2379017f9",
      "metadata": {
        "id": "3933954a-9274-4ea5-8ab3-53b2379017f9"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Test loop function\n",
        "\"\"\"\n",
        "def test_step(model:nn.Module,\n",
        "              data_loader: torch.utils.data.DataLoader,\n",
        "              loss_fn: nn.Module,\n",
        "              accuracy_fn,\n",
        "              device: torch.device = device):\n",
        "    test_loss, test_acc = 0, 0\n",
        "    model.to(device)\n",
        "    model.eval() # put model in eval mode\n",
        "    # turn on inference context manager\n",
        "    with torch.inference_mode():\n",
        "        for X, targets in data_loader:  # test batches\n",
        "            X = X.to(device)\n",
        "            targets = targets.to(device)\n",
        "            # 1. forward pass\n",
        "            test_pred = model(X)\n",
        "\n",
        "            # 2. Calculate the loss and accuracy\n",
        "            test_loss += loss_fn(test_pred, targets)\n",
        "            # Calculate accuracy\n",
        "            test_acc += accuracy_fn(y_true=targets,\n",
        "                y_pred= test_pred.argmax(dim=1) # logits to labels\n",
        "            )\n",
        "\n",
        "        # Adjust metrics and print out\n",
        "        test_loss /= len(data_loader)\n",
        "        test_acc /=len(data_loader)\n",
        "        print(f\"Test loss: {test_loss:.4f}  | Test accuracy: {test_acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a9e9d29-c986-4162-8d09-e9d9377a377f",
      "metadata": {
        "id": "4a9e9d29-c986-4162-8d09-e9d9377a377f"
      },
      "source": [
        "### 6.4 Model 1: Training and testing with our train and test step functions\n",
        "[chapter 110](https://youtu.be/V_xro1bcAuA&t=61050)\n",
        "get_timestamp(16,57,30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "505ba4c3-cede-4b2b-9415-e9497778ce2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "505ba4c3-cede-4b2b-9415-e9497778ce2a",
        "outputId": "e9141909-063a-4efe-ae82-781274e0ca2a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'get_timer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-8f6d9d999e8b>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mget_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#optional parameter for listing device used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch: {epoch}\\n---------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_timer' is not defined"
          ]
        }
      ],
      "source": [
        "# Import tqdm for progress bar DOESN't work in notebook for some reason\n",
        "from tqdm.auto import tqdm\n",
        "# Timer class is now implemented in helper_functions\n",
        "from helper_functions import accuracy_fn\n",
        "#from helper_functions import get_timer\n",
        "# set seed and start timer\n",
        "torch.manual_seed(42)\n",
        "# set epochs small for faster training time\n",
        "\n",
        "train_dataloader.dataset.data.to(device)\n",
        "#test_dataloader = test_dataloader.to(device)\n",
        "\n",
        "epochs = 3\n",
        "with get_timer(device) as timer: #optional parameter for listing device used\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        print(f\"Epoch: {epoch}\\n---------\")\n",
        "        train_step(data_loader=train_dataloader,\n",
        "            model=model_1,\n",
        "            loss_fn=loss_fn_1,\n",
        "            optimizer=optimizer_1,\n",
        "            accuracy_fn=accuracy_fn\n",
        "        )\n",
        "        test_step(data_loader=test_dataloader,\n",
        "            model=model_1,\n",
        "            loss_fn=loss_fn_1,\n",
        "            accuracy_fn=accuracy_fn\n",
        "        )\n",
        "total_train_time_model_1 = timer.elapsed_time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1e338ab-3816-4832-8b10-ac1c2d607cb6",
      "metadata": {
        "id": "a1e338ab-3816-4832-8b10-ac1c2d607cb6"
      },
      "source": [
        "### 6.5 Evaluating Model 1 device-agnostic eval_model |[chapter 111](https://youtu.be/V_xro1bcAuA&t=61763)\n",
        "\n",
        "I already fixed this in the original version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8195e7b6-e22f-4817-b3b5-d8349458de31",
      "metadata": {
        "id": "8195e7b6-e22f-4817-b3b5-d8349458de31"
      },
      "outputs": [],
      "source": [
        "# Calculate model_0 results on test dataset\n",
        "# note: loss function should be CrossEntropy for this model\n",
        "model_0_results = eval_model(model=model_0, data_loader=test_dataloader,\n",
        "                            loss_fn=loss_fn, accuracy_fn=accuracy_fn,\n",
        "                             device= device\n",
        ")\n",
        "print(model_0_results)\n",
        "\n",
        "model_1_results = eval_model(model=model_1, data_loader=test_dataloader,\n",
        "                            loss_fn=loss_fn_1, accuracy_fn=accuracy_fn,\n",
        "                             device= device\n",
        ")\n",
        "print(model_1_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6d5a12c-a67b-4921-8f09-44088953fee9",
      "metadata": {
        "id": "a6d5a12c-a67b-4921-8f09-44088953fee9"
      },
      "outputs": [],
      "source": [
        "total_train_time_model_0,total_train_time_model_1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eae0007-e3d2-44cc-ba05-67e2f3ce422a",
      "metadata": {
        "id": "0eae0007-e3d2-44cc-ba05-67e2f3ce422a"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30090554-8154-4456-ba9e-2bf820907701",
      "metadata": {
        "id": "30090554-8154-4456-ba9e-2bf820907701"
      },
      "source": [
        "## 7. Model 2 Building a convolutional model  [chapter 112](https://youtu.be/V_xro1bcAuA&t=62012)  \n",
        "\n",
        "Time to create a Convolutional Neural Network better know as a CNN (also know as ConvNet).\n",
        "We will duplicate the TinyVGG model depicted on [cnn explainer](https://poloclub.github.io/cnn-explainer/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be66f64d-a49a-4426-9bfa-ca9474a81ab6",
      "metadata": {
        "id": "be66f64d-a49a-4426-9bfa-ca9474a81ab6"
      },
      "outputs": [],
      "source": [
        "# Create device-agnostic code\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "288529c8-479a-41be-939a-f033b12b4689",
      "metadata": {
        "id": "288529c8-479a-41be-939a-f033b12b4689"
      },
      "outputs": [],
      "source": [
        "# Create a convolution neural network\n",
        "class FashionMNISTModel_V2(nn.Module):\n",
        "    \"\"\"\n",
        "    Model archicture copying TinyVGG from:\n",
        "    https://poloclub.github.io/cnn-explainer/\n",
        "    \"\"\"\n",
        "    def __init__(self, input_shape: int, hidden_units:int, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d( in_channels=input_shape,\n",
        "                     out_channels=hidden_units,\n",
        "                     kernel_size=3,\n",
        "                     stride=1,\n",
        "                     padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d( in_channels=hidden_units,\n",
        "                     out_channels=hidden_units,\n",
        "                     kernel_size=3,\n",
        "                     stride=1,\n",
        "                     padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         stride=2) # default stride is same as kernel size\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        # to figure out the input shape for the linear layer since each layer above shrinks\n",
        "        # the image down, run a test image throught the first 2 layers and multiply the shape values together\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(), # default is dim=1, makes sense when we want to flatten an image but leave the color(zero dim alone)\n",
        "            # Where did this in_features shape come from?\n",
        "            # It's because each layer of our network compresses and changes the shape of our input data.\n",
        "            nn.Linear(in_features=hidden_units*7*7,\n",
        "                      out_features=output_shape)\n",
        "        )\n",
        "\n",
        "\n",
        "    # change this to fusion code to make gpu go brrr\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        return self.classifier(self.block_2(self.block_1(x)))\n",
        "        #print(f\"shape being passed to block_1: {x.shape}\")\n",
        "        #x = self.block_1(x)\n",
        "        #print(f\"shape being passed to block_2: {x.shape}\")\n",
        "        #x = self.block_2(x)\n",
        "        #print(f\"shape being passed to block_3: {x.shape}\")\n",
        "        #x = self.block_3(x)\n",
        "        #print(f\"shape being passed to classifier: {x.shape}\")\n",
        "        #x = self.classifier(x)\n",
        "        #print(x.shape)\n",
        "        #return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eecae10c-e07f-4cef-ad02-d6a58080a2e0",
      "metadata": {
        "id": "eecae10c-e07f-4cef-ad02-d6a58080a2e0"
      },
      "outputs": [],
      "source": [
        "\n",
        "torch.manual_seed(42)\n",
        "model_2 = FashionMNISTModel_V2(input_shape=1,\n",
        "    hidden_units=10,\n",
        "    output_shape=len(class_names)).to(device)\n",
        "\n",
        "model_2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90c77e7a-357a-4cc4-a335-17dc2fa8779c",
      "metadata": {
        "id": "90c77e7a-357a-4cc4-a335-17dc2fa8779c"
      },
      "source": [
        "Nice!\n",
        "\n",
        "Our biggest model yet!\n",
        "\n",
        "What we've done is a common practice in machine learning.\n",
        "\n",
        "Find a model architecture somewhere and replicate it with code."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4311a62b-c323-4158-b408-0cf5c61138a1",
      "metadata": {
        "id": "4311a62b-c323-4158-b408-0cf5c61138a1"
      },
      "source": [
        "### 7.1 Stepping through `nn.Conv2d()`\n",
        "\n",
        "We could start using our model above and see what happens but let's first step through the two new layers we've added:\n",
        "* [`nn.Conv2d()`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html), also known as a convolutional layer.\n",
        "* [`nn.MaxPool2d()`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html), also known as a max pooling layer.\n",
        "\n",
        "> **Question:** What does the \"2d\" in `nn.Conv2d()` stand for?\n",
        ">\n",
        "> The 2d is for 2-dimensional data. As in, our images have two dimensions: height and width. Yes, there's color channel dimension but each of the color channel dimensions have two dimensions too: height and width.\n",
        ">\n",
        "> For other dimensional data (such as 1D for text or 3D for 3D objects) there's also `nn.Conv1d()` and `nn.Conv3d()`.\n",
        "\n",
        "To test the layers out, let's create some toy data just like the data used on CNN Explainer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f335a03-86b5-4e88-a6a6-4084a7f87ee4",
      "metadata": {
        "id": "3f335a03-86b5-4e88-a6a6-4084a7f87ee4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Create sample batch of random numbers with same size as image batch\n",
        "images = torch.randn(size=(32, 3, 64, 64)) # [batch_size, color_channels, height, width]\n",
        "test_image = images[0] # get a single image for testing\n",
        "print(f\"Image batch shape: {images.shape} -> [batch_size, color_channels, height, width]\")\n",
        "print(f\"Single image shape: {test_image.shape} -> [color_channels, height, width]\")\n",
        "print(f\"Single image pixel values:\\n{test_image}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfa75bc1-12a8-49a6-9acf-548b8ffdee65",
      "metadata": {
        "id": "dfa75bc1-12a8-49a6-9acf-548b8ffdee65"
      },
      "source": [
        "Let's create an example `nn.Conv2d()` with various parameters:\n",
        "* `in_channels` (int) - Number of channels in the input image.\n",
        "* `out_channels` (int) - Number of channels produced by the convolution.\n",
        "* `kernel_size` (int or tuple) - Size of the convolving kernel/filter.\n",
        "* `stride` (int or tuple, optional) - How big of a step the convolving kernel takes at a time. Default: 1.\n",
        "* `padding` (int, tuple, str) - Padding added to all four sides of input. Default: 0.\n",
        "\n",
        "![example of going through the different parameters of a Conv2d layer](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-conv2d-layer.gif)\n",
        "\n",
        "*Example of what happens when you change the hyperparameters of a `nn.Conv2d()` layer.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e6ac917-5829-42ec-af54-cd3de112c567",
      "metadata": {
        "id": "7e6ac917-5829-42ec-af54-cd3de112c567"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "#Create a CNN with the same dimensionas TinyVGG\n",
        "\n",
        "conv_layer = nn.Conv2d(in_channels=3,\n",
        "                      out_channels=10,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=0) # also try using \"valid\" or \"same\" here\n",
        "out =conv_layer(test_image)\n",
        "test_image.shape, out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ef28932-49c3-4816-b92b-0c6e58a299ab",
      "metadata": {
        "id": "7ef28932-49c3-4816-b92b-0c6e58a299ab"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2f661ba-0ceb-4d64-ab66-3619a1d45a90",
      "metadata": {
        "id": "d2f661ba-0ceb-4d64-ab66-3619a1d45a90"
      },
      "outputs": [],
      "source": [
        "conv_layer.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc747868-fa7c-40c6-8c16-66dee2bfad49",
      "metadata": {
        "id": "bc747868-fa7c-40c6-8c16-66dee2bfad49"
      },
      "outputs": [],
      "source": [
        "# Get shapes of weight and bias tensors within conv_layer_2\n",
        "print(f\"conv_layer weight shape: \\n{conv_layer.weight.shape} -> [out_channels=10, in_channels=3, kernel_size=5, kernel_size=5]\")\n",
        "print(f\"\\nconv_layer bias shape: \\n{conv_layer.bias.shape} -> [out_channels=10]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f454c6f-f2b0-4140-9315-888166872731",
      "metadata": {
        "id": "7f454c6f-f2b0-4140-9315-888166872731"
      },
      "source": [
        "### 7.2 Stepping through `nn.MaxPool2d()` [chapter 115](https://youtu.be/V_xro1bcAuA&t=64606)  \n",
        "\n",
        "Now let's check out what happens when we move data through `nn.MaxPool2d()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e604f590-019e-4ef4-8366-d9e3367b19b9",
      "metadata": {
        "id": "e604f590-019e-4ef4-8366-d9e3367b19b9"
      },
      "outputs": [],
      "source": [
        "# Print out original image shape without and with unsqueezed dimension\n",
        "print(f\"Test image original shape: {test_image.shape}\")\n",
        "print(f\"Test image with unsqueezed dimension: {test_image.unsqueeze(dim=0).shape}\")\n",
        "\n",
        "# newer versions of Conv2d accept either a batch of images or a single image# Create a sample nn.MaxPoo2d() layer\n",
        "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "# Pass data through just the conv_layer\n",
        "test_image_through_conv = conv_layer(test_image.unsqueeze(dim=0))\n",
        "print(f\"Shape after going through conv_layer(): {test_image_through_conv.shape}\")\n",
        "\n",
        "# now pass the data thru the maxpool layer\n",
        "test_image_through_conv_and_max_pool = max_pool_layer(test_image_through_conv)\n",
        "print(f\"Shape after passing through the maxPool layer: {test_image_through_conv_and_max_pool.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aee31e2d-c6eb-4163-855f-30f5e54c4803",
      "metadata": {
        "id": "aee31e2d-c6eb-4163-855f-30f5e54c4803"
      },
      "source": [
        "Notice the change in the shapes of what's happening in and out of a `nn.MaxPool2d()` layer.\n",
        "\n",
        "The `kernel_size` of the `nn.MaxPool2d()` layer will affect the size of the output shape.\n",
        "\n",
        "In our case, the shape halves from a `62x62` image to `31x31` image.\n",
        "\n",
        "Let's see this work with a smaller tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5743e843-eb56-489e-be1e-edd044558969",
      "metadata": {
        "id": "5743e843-eb56-489e-be1e-edd044558969"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "# Create a random tensor with similiar number of dimension to our images\n",
        "random_tensor = torch.randn(size=(1,1,2,2))\n",
        "print(f\"Random_tensor:\\n{random_tensor}\")\n",
        "print(f\"Random_tensor shape :{random_tensor.shape}\")\n",
        "\n",
        "# Pass the random tensor through the max pool layer\n",
        "max_pool_tensor = max_pool_layer(random_tensor)\n",
        "print(f\"\\nMax pool tensor:\\n{max_pool_tensor} <- this is the maximum value from random_tensor\")\n",
        "print(f\"Max pool tensor shape: {max_pool_tensor.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d63b2559-2f80-4d81-b759-709ebab3a2e0",
      "metadata": {
        "id": "d63b2559-2f80-4d81-b759-709ebab3a2e0"
      },
      "source": [
        "### 7.3 Setup a loss function and optimizer for `model_2` | [chapter 117](https://youtu.be/V_xro1bcAuA&t=66383)\n",
        "\n",
        "We've stepped through the layers in our first CNN enough.\n",
        "\n",
        "But remember, if something still isn't clear, try starting small.\n",
        "\n",
        "Pick a single layer of a model, pass some data through it and see what happens.\n",
        "\n",
        "Now it's time to move forward and get to training!\n",
        "\n",
        "Let's setup a loss function and an optimizer.\n",
        "\n",
        "We'll use the functions as before, `nn.CrossEntropyLoss()` as the loss function (since we're working with multi-class classification data).\n",
        "\n",
        "And `torch.optim.SGD()` as the optimizer to optimize `model_2.parameters()` with a learning rate of `0.1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46f6a45d-fcd4-4e00-8ed6-eb0300e7e651",
      "metadata": {
        "id": "46f6a45d-fcd4-4e00-8ed6-eb0300e7e651"
      },
      "outputs": [],
      "source": [
        "# Setup loss function/eval metrics/optimizer\n",
        "from tqdm.auto import tqdm\n",
        "# Timer class is now implemented in helper_functions\n",
        "from helper_functions import accuracy_fn,get_timer\n",
        "# Setup loss and optimizer\n",
        "loss_fn_2 = nn.CrossEntropyLoss()\n",
        "optimizer_2 = torch.optim.SGD(params=model_2.parameters(),\n",
        "                             lr=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3dd288a-bf16-4c26-9525-8ef7cf693861",
      "metadata": {
        "id": "a3dd288a-bf16-4c26-9525-8ef7cf693861"
      },
      "outputs": [],
      "source": [
        "list(model_2.parameters())[0].device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06cceada-a0cc-464e-9ba0-55e9915612f3",
      "metadata": {
        "id": "06cceada-a0cc-464e-9ba0-55e9915612f3"
      },
      "outputs": [],
      "source": [
        "image_v2,label = train_data[2]\n",
        "print(f\"image_v2.shape: {image_v2.shape}\")\n",
        "print(f\"model is loaded on {list(model_2.parameters())[0].device}\")\n",
        "print(f\"image_v2 is on {image_v2.device}\")\n",
        "\n",
        "#test_image.to(device)\n",
        "pred = model_2 (image_v2.unsqueeze(dim=0).to(device))\n",
        "#print (f\"\\n{pred}\")\n",
        "#plt.imshow(pred[0].detach().to('cpu'), cmap=\"gray\")\n",
        "#plt.title(class_names[label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19377337-d43c-412e-a2c8-34dedb21e8af",
      "metadata": {
        "id": "19377337-d43c-412e-a2c8-34dedb21e8af"
      },
      "outputs": [],
      "source": [
        "#print (model_2.image_block_1.shape)\n",
        "#plt.imshow(model_2.image_block_1[9].to('cpu'), cmap=\"gray\")\n",
        "\n",
        "#print (model_2.image_block_2.shape)\n",
        "#plt.imshow(model_2.image_block_2[0].to('cpu'), cmap=\"gray\")\n",
        "\n",
        "#print (model_2.image_classifier.shape)\n",
        "#plt.imshow(model_2.image_classifier.to('cpu'), cmap=\"gray\")\n",
        "\n",
        "print(pred,label)\n",
        "\n",
        "#plt.title(class_names[label])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fcdeeeb-05b9-472a-926a-8db0cccf7751",
      "metadata": {
        "id": "4fcdeeeb-05b9-472a-926a-8db0cccf7751"
      },
      "source": [
        "### 7.3 Using train and test step functions to train model | [chapter 118](https://youtu.be/V_xro1bcAuA&t=66542)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "211447a5-d05f-4ede-8a6c-bd79ab071e54",
      "metadata": {
        "id": "211447a5-d05f-4ede-8a6c-bd79ab071e54"
      },
      "outputs": [],
      "source": [
        "\n",
        "# set seed and start timer\n",
        "#torch.manual_seed(42)\n",
        "\n",
        "#train_dataloader.dataset.data.to(device)\n",
        "\n",
        "model_2.to(device)\n",
        "epochs = 3\n",
        "with get_timer(device) as timer: #optional parameter for listing device used\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        print(f\"Epoch: {epoch}\\n---------\")\n",
        "        train_step(data_loader=train_dataloader,\n",
        "            model=model_2,\n",
        "            loss_fn=loss_fn_2,\n",
        "            optimizer=optimizer_2,\n",
        "            accuracy_fn=accuracy_fn\n",
        "        )\n",
        "        test_step(data_loader=test_dataloader,\n",
        "            model=model_2,\n",
        "            loss_fn=loss_fn_2,\n",
        "            accuracy_fn=accuracy_fn\n",
        "        )\n",
        "total_train_time_model_2 = timer.elapsed_time\n",
        "print (f\"Total train time {total_train_time_model_2} on device; {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "929b958d-7cbc-4d8b-8c67-13e488159364",
      "metadata": {
        "id": "929b958d-7cbc-4d8b-8c67-13e488159364"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Get results for model 2\n",
        "model_2_results = eval_model(model=model_2, data_loader=test_dataloader,\n",
        "                             loss_fn=loss_fn_2, accuracy_fn=accuracy_fn,\n",
        "                             device=device\n",
        ")\n",
        "print( model_2_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fd8ae02-c8b8-4da6-baae-0fe2c2e20847",
      "metadata": {
        "id": "6fd8ae02-c8b8-4da6-baae-0fe2c2e20847"
      },
      "outputs": [],
      "source": [
        "print( model_0_results)\n",
        "print( model_1_results)\n",
        "print( model_2_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52cdf56d-56bf-4db0-afd4-cc4e9f828f11",
      "metadata": {
        "id": "52cdf56d-56bf-4db0-afd4-cc4e9f828f11"
      },
      "source": [
        "### 7.4 Comparing results of our modelling experiments | [chapter 119](https://youtu.be/V_xro1bcAuA&t=67017)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "454b9893-f874-436f-8f76-f099521f25ee",
      "metadata": {
        "id": "454b9893-f874-436f-8f76-f099521f25ee"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "compare_results = pd.DataFrame([model_0_results,\n",
        "                               model_1_results,\n",
        "                               model_2_results])\n",
        "compare_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d25b5ee-d9ec-45ca-aeed-b9f12b5f18be",
      "metadata": {
        "id": "5d25b5ee-d9ec-45ca-aeed-b9f12b5f18be"
      },
      "outputs": [],
      "source": [
        "# Add training time to result comparision\n",
        "compare_results[\"training_time\"] = [total_train_time_model_0,\n",
        "                                   total_train_time_model_1,\n",
        "                                   total_train_time_model_2]\n",
        "compare_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b852977-7534-4640-a251-21011dce6a7a",
      "metadata": {
        "id": "8b852977-7534-4640-a251-21011dce6a7a"
      },
      "outputs": [],
      "source": [
        "# visualize our model results\n",
        "compare_results.set_index('model_name')['model_acc'].plot(kind=\"barh\")\n",
        "plt.xlabel(\"accuracy (%)\")\n",
        "plt.ylabel(\"model\");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "953e4c6a-3887-4757-86b3-65ad91038aba",
      "metadata": {
        "id": "953e4c6a-3887-4757-86b3-65ad91038aba"
      },
      "source": [
        "## 9. Making Predictions on random test samples with the best trained model | [Chapter 120](https://youtu.be/V_xro1bcAuA&t=67463)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a94c01f-1383-44d9-9391-e70ec6770f04",
      "metadata": {
        "id": "9a94c01f-1383-44d9-9391-e70ec6770f04"
      },
      "outputs": [],
      "source": [
        "def make_predictions(model: torch.nn.Module,\n",
        "                    data: list,\n",
        "                    device: torch.device = device):\n",
        "    pred_probs = []\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for sample in data:\n",
        "            # prepare sample (add a batch dimension and pass to device)\n",
        "            sample = torch.unsqueeze(sample,dim=0).to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            pred_logit = model(sample)\n",
        "\n",
        "            # Get prediction probablilty\n",
        "            pred_prob = torch.softmax(pred_logit.squeeze(),dim=0)\n",
        "\n",
        "            # Get pred_prob off the gpu for further calculations\n",
        "            pred_probs.append(pred_prob.cpu())\n",
        "\n",
        "    # Stack the pred_probs to turn list into a tensor\n",
        "    return torch.stack(pred_probs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "830fab70-7c42-4636-bd16-d09ca999fc32",
      "metadata": {
        "id": "830fab70-7c42-4636-bd16-d09ca999fc32"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "#random.seed(42)\n",
        "test_samples = []\n",
        "test_labels = []\n",
        "for sample, label in random.sample(list(test_data),k=9):\n",
        "    test_samples.append(sample)\n",
        "    test_labels.append(label)\n",
        "\n",
        "#view the first sample shape\n",
        "test_samples[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f40a5f0c-ff73-4cda-a8fb-f3554514b198",
      "metadata": {
        "id": "f40a5f0c-ff73-4cda-a8fb-f3554514b198"
      },
      "outputs": [],
      "source": [
        "plt.imshow(test_samples[0].squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[test_labels[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71381798-0b85-4166-9b91-9f30d40f5c37",
      "metadata": {
        "id": "71381798-0b85-4166-9b91-9f30d40f5c37"
      },
      "outputs": [],
      "source": [
        "# Make prediction\n",
        "pred_probs = make_predictions(model=model_2,\n",
        "                             data=test_samples)\n",
        "\n",
        "# View the first 2 prediction probabilities\n",
        "pred_probs[:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36d2546d-c05b-4138-94ea-c2672a3366e9",
      "metadata": {
        "id": "36d2546d-c05b-4138-94ea-c2672a3366e9"
      },
      "outputs": [],
      "source": [
        "# convert predictions probabilities to labels\n",
        "pred_classes = pred_probs.argmax(dim=1)\n",
        "pred_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce6bddab-191d-4873-983d-52f03f56d5fd",
      "metadata": {
        "id": "ce6bddab-191d-4873-983d-52f03f56d5fd"
      },
      "outputs": [],
      "source": [
        "test_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13b22103-983c-4f94-b46a-8e28440bd8aa",
      "metadata": {
        "id": "13b22103-983c-4f94-b46a-8e28440bd8aa"
      },
      "source": [
        "### 9.1 Plotting our best model predictions on the test set and evaluating them\n",
        "[Chapter 121](https://youtu.be/V_xro1bcAuA&t=68162)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07d95786-838a-4ee5-8d23-2efb29e0ef7e",
      "metadata": {
        "id": "07d95786-838a-4ee5-8d23-2efb29e0ef7e"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(9,9))\n",
        "nrows = 3\n",
        "ncols = 3\n",
        "for i, sample in enumerate(test_samples):\n",
        "    # Create subplot\n",
        "    plt.subplot(nrows, ncols, i+1)\n",
        "    # Plot the target image\n",
        "    plt.imshow(sample.squeeze(), cmap=\"gray\")\n",
        "\n",
        "    # find the prediction (in text form)\n",
        "    pred_label = class_names[pred_classes[i]]\n",
        "\n",
        "    # Get the truth label (in text form)\n",
        "    truth_label = class_names[test_labels[i]]\n",
        "\n",
        "    # Create a title\n",
        "    title_text = f\"Pred:{pred_label} | Truth: {truth_label}\"\n",
        "\n",
        "    # Check for equality between pred and truth and change color of title text\n",
        "    if pred_label == truth_label:\n",
        "        plt.title(title_text, fontsize=10, c='g') # Green text if prediction was correct\n",
        "    else:\n",
        "        plt.title(title_text, fontsize=10, c='r') # Red text for incorrect prediction\n",
        "\n",
        "    plt.axis(False)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03fb3c4c-f51d-4d0d-bfbd-d922b44b5afa",
      "metadata": {
        "id": "03fb3c4c-f51d-4d0d-bfbd-d922b44b5afa"
      },
      "source": [
        "## 10. Making a confusion matrix for further prediction evaluation\n",
        "\n",
        "Making predictions across whole test dataset and importing libraries to plot a confusion matrix | [Chapter 122](https://youtu.be/V_xro1bcAuA&t=68653)\n",
        "A confusion matrix is a fantastic way of evaluating your classification model\n",
        "\n",
        "1. Make Predictions with our trained model on the test dataset\n",
        "2. Make a confusion matrix `torchmetrics.ConfusionMatrix`\n",
        "3. Plot the confusion matrix using `mlxtend.plotting.plot_confusion_matrix()`\n",
        "\n",
        "from command promp in correct virtual environment\n",
        "\n",
        "conda install -c conda-forge torchmetrics\n",
        "conda install -c conda-forge mlxtend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d75dc5f7-52bb-4569-99af-590cacd8dc1f",
      "metadata": {
        "id": "d75dc5f7-52bb-4569-99af-590cacd8dc1f"
      },
      "outputs": [],
      "source": [
        "# Import tqdm.auto   doesn't work in jupyter\n",
        "from tqdm.auto import tqdm\n",
        "import torchmetrics\n",
        "import mlxtend\n",
        "\n",
        "print(torchmetrics.__version__)\n",
        "# 1. Make predictions with traind model\n",
        "y_preds = []\n",
        "model_2.eval()\n",
        "with torch.inference_mode():\n",
        "    for X, y in tqdm(test_dataloader, desc=\"Making predictions...\"):\n",
        "        # Send data to target device\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        y_logit = model_2(X)\n",
        "        y_pred = torch.softmax(y_logit.squeeze(), dim=0).argmax(dim=1)\n",
        "        y_preds.append(y_pred.cpu())\n",
        "\n",
        "# Concatenate into a tensor\n",
        "#print(y_preds)\n",
        "y_pred_tensor = torch.cat(y_preds)\n",
        "y_pred_tensor[:5]\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b77207b5-6836-4ed5-a524-97b3eca10def",
      "metadata": {
        "id": "b77207b5-6836-4ed5-a524-97b3eca10def"
      },
      "outputs": [],
      "source": [
        "y_pred_tensor,test_data.targets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3095b12a-8cae-44a9-9ad9-ce07407a255d",
      "metadata": {
        "id": "3095b12a-8cae-44a9-9ad9-ce07407a255d"
      },
      "source": [
        "[Chapter 123](https://youtu.be/V_xro1bcAuA&t=69574)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3914095-cdd4-424c-a6e0-90db6cce4fec",
      "metadata": {
        "id": "b3914095-cdd4-424c-a6e0-90db6cce4fec"
      },
      "outputs": [],
      "source": [
        "from torchmetrics import ConfusionMatrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "# 2. setup Confusion instance and compare predictions to targets\n",
        "confmat = ConfusionMatrix(task=\"multiclass\",num_classes=len(class_names))\n",
        "confmat_tensor = confmat(preds=y_pred_tensor,\n",
        "                        target=test_data.targets)\n",
        "\n",
        "#3.Plot the matrix from mlxtend\n",
        "fig, ax = plot_confusion_matrix(\n",
        "    conf_mat=confmat_tensor.numpy(),\n",
        "    class_names=class_names,\n",
        "    figsize=(10,7)\n",
        ")\n",
        "fig, ax"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13111899-dfc1-4379-8263-ad1bdc9923ac",
      "metadata": {
        "id": "13111899-dfc1-4379-8263-ad1bdc9923ac"
      },
      "source": [
        "## 11. Save and load best performing model. [Chapter 124](https://youtu.be/V_xro1bcAuA&t=69990)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "124e82f0-71a7-4bb0-8eee-962a32af6959",
      "metadata": {
        "id": "124e82f0-71a7-4bb0-8eee-962a32af6959"
      },
      "outputs": [],
      "source": [
        "model_2.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "504a5fb7-b4ab-4c50-8321-4627fe4e64eb",
      "metadata": {
        "id": "504a5fb7-b4ab-4c50-8321-4627fe4e64eb"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# 1. Create models directory   (already exists... do I need to do this step?)\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 2. Create the model save path\n",
        "MODEL_NAME = \"03_pytorch_computer_vision_model_2.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "# 3. Save the models state_dict\n",
        "print(f\"Saving the model to: {MODEL_SAVE_PATH}\")\n",
        "\n",
        "# only saves the models learned parameters, rebuilding the matrix required the code above\n",
        "# Things I need, model class (loss_fn and optimizers need be the same?)\n",
        "torch.save(obj=model_2.state_dict(),\n",
        "          f=MODEL_SAVE_PATH)\n",
        "# a measly 34.8 KB (35.634 bytes) file compare that to the gpts models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42e12003-4e63-47ae-be0a-d30d4dd1131c",
      "metadata": {
        "id": "42e12003-4e63-47ae-be0a-d30d4dd1131c"
      },
      "outputs": [],
      "source": [
        "# Check the saved file path\n",
        "# Linux\n",
        "#!ls -l models/\\03_pytorch_computer_vision_model_2.pth\n",
        "#Windows\n",
        "!dir -l models\\\\\\03_pytorch_computer_vision_model_2.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af540dbc-701d-468f-a448-1f8347f542c8",
      "metadata": {
        "id": "af540dbc-701d-468f-a448-1f8347f542c8"
      },
      "source": [
        "### 11.1 Loading it back in   DON'T lose or change the class definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f4774ad-eb4b-40e7-baa2-36d22b5eb499",
      "metadata": {
        "id": "2f4774ad-eb4b-40e7-baa2-36d22b5eb499"
      },
      "outputs": [],
      "source": [
        "model_2_reloaded = FashionMNISTModel_V2(input_shape=1,\n",
        "                                       hidden_units=10,\n",
        "                                       output_shape=len(class_names))\n",
        "\n",
        "# load in the saved state_dict\n",
        "model_2_reloaded.load_state_dict(torch.load(f=MODEL_SAVE_PATH,\n",
        "                                           weights_only=True))\n",
        "# default is weights_only = False which is unsafe,\n",
        "# any arbitrary code can be loaded and executed\n",
        "# This limits the functions that could be executed during unpickling.\n",
        "# Arbitrary objects will no longer be allowed to be loaded via this mode\n",
        "# unless they are explicitly allowlisted by the user\n",
        "# via `torch.serialization.add_safe_globals`.\n",
        "# We recommend you start setting `weights_only=True` for any use case\n",
        "# where you don't have full control of the loaded file.\n",
        "model_2_reloaded.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2aebe863-dfe6-4ad5-a281-c8d922a02d8a",
      "metadata": {
        "id": "2aebe863-dfe6-4ad5-a281-c8d922a02d8a"
      },
      "outputs": [],
      "source": [
        "# use model as above evaluating\n",
        "model_2_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbab1003-2f7c-46d9-ac8b-6d71ef8accbe",
      "metadata": {
        "id": "fbab1003-2f7c-46d9-ac8b-6d71ef8accbe"
      },
      "outputs": [],
      "source": [
        "\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "model_2_reloaded_results = eval_model(\n",
        "    model=model_2_reloaded,\n",
        "    data_loader=test_dataloader,\n",
        "    loss_fn=loss_fn,\n",
        "    accuracy_fn=accuracy_fn,\n",
        "    device=device\n",
        ")\n",
        "model_2_reloaded_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1d9a70d-055c-4a36-92d9-3e85280f5140",
      "metadata": {
        "id": "e1d9a70d-055c-4a36-92d9-3e85280f5140"
      },
      "source": [
        "We can find out if two tensors are close to each other using `torch.isclose()` and passing in a tolerance level of closeness via the parameters `atol` (absolute tolerance) and `rtol` (relative tolerance).\n",
        "\n",
        "If our model's results are close, the output of `torch.isclose()` should be true."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e5fd0c0-459a-4f87-a608-22c803d32f9d",
      "metadata": {
        "id": "9e5fd0c0-459a-4f87-a608-22c803d32f9d"
      },
      "outputs": [],
      "source": [
        "# Check to see it the results are close to each other (if they are far off, there may be an error)\n",
        "torch.isclose(torch.tensor(model_0_results[\"model_loss\"]),\n",
        "             torch.tensor(model_2_reloaded_results[\"model_loss\"]),\n",
        "             atol=1e-08, # absolute tolerance, if needed, the default may be fine\n",
        "             rtol=0.0001 # relative error, again if needed to loosen up \"closeness\"\n",
        "             )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efa8be20-eced-4fe5-808c-0770bb5b185a",
      "metadata": {
        "id": "efa8be20-eced-4fe5-808c-0770bb5b185a"
      },
      "source": [
        "## Exercises\n",
        "### Pytorch computer vision summary and extra-curriculum | [Chapter 125](https://youtu.be/V_xro1bcAuA&t=70678)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efc31664-4b81-45ee-ac55-1f3d656de355",
      "metadata": {
        "id": "efc31664-4b81-45ee-ac55-1f3d656de355"
      },
      "source": [
        "Check the deeo_learning_main notebook 3 for details or\n",
        "\n",
        "**Resources:**\n",
        "* [Exercise template notebook for 03](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/03_pytorch_computer_vision_exercises.ipynb)\n",
        "* [Example solutions notebook for 03](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/03_pytorch_computer_vision_exercise_solutions.ipynb) (try the exercises *before* looking at this)\n",
        "\n",
        "Things to try:\n",
        "1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebea02f7-833d-43cb-b93b-33df97788bcc",
      "metadata": {
        "id": "ebea02f7-833d-43cb-b93b-33df97788bcc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.__version__\n",
        "import numpy\n",
        "numpy.__version__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c298ca32-f158-4132-99f7-a259a642e99f",
      "metadata": {
        "id": "c298ca32-f158-4132-99f7-a259a642e99f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os.path import exists\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import log_softmax, pad\n",
        "import math\n",
        "import copy\n",
        "import time\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "import pandas as pd\n",
        "import altair as alt\n",
        "#from torchtext.data.functional import to_map_style_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import torchtext.datasets as datasets\n",
        "import spacy\n",
        "import GPUtil\n",
        "import warnings\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "import torch.distributed as dist\n",
        "import torch.multiprocessing as mp\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "\n",
        "\n",
        "# Set to False to skip notebook execution (e.g. for debugging)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "RUN_EXAMPLES = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47296cfa-c8e4-41b8-8dfa-0b19431d4925",
      "metadata": {
        "id": "47296cfa-c8e4-41b8-8dfa-0b19431d4925"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d8fdd67508414dd29c08de4e8f12ef32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01378f090bd546e48d401732965f5067",
              "IPY_MODEL_431d7b29c7994a3298a2e0d679ebe4de",
              "IPY_MODEL_2e61be13483c42d29bbe600668606025"
            ],
            "layout": "IPY_MODEL_9762961383b84f23b8e0e3246c664d03"
          }
        },
        "01378f090bd546e48d401732965f5067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_053d77aea0c448e1a0931604588aa3d1",
            "placeholder": "​",
            "style": "IPY_MODEL_63172b8fa9ea4744869dfd7d461bc6d3",
            "value": "100%"
          }
        },
        "431d7b29c7994a3298a2e0d679ebe4de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82f94f3b8c9c4dd58d209fa793302173",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f3a8bd909584485a6464e91266f060b",
            "value": 3
          }
        },
        "2e61be13483c42d29bbe600668606025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0ccaf288eb548e09ab4b1f08e73af4c",
            "placeholder": "​",
            "style": "IPY_MODEL_84c135108f024f0b8d437443847cb9f7",
            "value": " 3/3 [00:25&lt;00:00,  8.21s/it]"
          }
        },
        "9762961383b84f23b8e0e3246c664d03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "053d77aea0c448e1a0931604588aa3d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63172b8fa9ea4744869dfd7d461bc6d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82f94f3b8c9c4dd58d209fa793302173": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f3a8bd909584485a6464e91266f060b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0ccaf288eb548e09ab4b1f08e73af4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84c135108f024f0b8d437443847cb9f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81aa75b793bd4b64b4782d4b36441d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_752ebac5c0024e86a179767f1eb0892b",
              "IPY_MODEL_2290fa4c51bc4fcaa95b462832e9fde7",
              "IPY_MODEL_e2f7d4f2a04f4ed4b6e5a7001c99807d"
            ],
            "layout": "IPY_MODEL_6541cbe564504e15bef9f2a436a05bc1"
          }
        },
        "752ebac5c0024e86a179767f1eb0892b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0f9d6edde734dc5970954bb5460a0d3",
            "placeholder": "​",
            "style": "IPY_MODEL_2f38f3f3bc564ebf92a35775e0d7b8c6",
            "value": "100%"
          }
        },
        "2290fa4c51bc4fcaa95b462832e9fde7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae6ac5549f054948bd3b6801649b352c",
            "max": 157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f3dfe0ae8e947e59d08250f28bf402f",
            "value": 157
          }
        },
        "e2f7d4f2a04f4ed4b6e5a7001c99807d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84fa1b5c24404feb8d99b6d93c748f4b",
            "placeholder": "​",
            "style": "IPY_MODEL_c29b6b5497a3439fb0e6cf5faa155d2b",
            "value": " 157/157 [00:01&lt;00:00, 138.33it/s]"
          }
        },
        "6541cbe564504e15bef9f2a436a05bc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0f9d6edde734dc5970954bb5460a0d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f38f3f3bc564ebf92a35775e0d7b8c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae6ac5549f054948bd3b6801649b352c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f3dfe0ae8e947e59d08250f28bf402f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84fa1b5c24404feb8d99b6d93c748f4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c29b6b5497a3439fb0e6cf5faa155d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}